{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ms9WY7esN3OP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653163451360,"user_tz":-120,"elapsed":24863,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"67485cbb-4809-4819-df40-6bf9a4d17287"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at ./mydata\n"]}],"source":["from google.colab import drive\n","drive.mount('./mydata')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mgEda4XUdZOp","executionInfo":{"status":"ok","timestamp":1653163451362,"user_tz":-120,"elapsed":16,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["import sys\n","sys.path.append('./mydata/MyDrive/COQAR')\n","sys.path.append('./mydata/MyDrive/COQAR/rewriting')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jTW4y6iLdlPG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653163476564,"user_tz":-120,"elapsed":25214,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"b6750e6d-e386-4d02-886a-75b3c2616478"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 60.4 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n","Collecting rouge_metric\n","  Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 5.2 MB/s \n","\u001b[?25hInstalling collected packages: rouge-metric\n","Successfully installed rouge-metric-1.0.1\n","Collecting nltk==3.6.5\n","  Downloading nltk-3.6.5-py3-none-any.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (1.1.0)\n","Collecting regex>=2021.8.3\n","  Downloading regex-2022.4.24-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n","\u001b[K     |████████████████████████████████| 749 kB 47.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (4.64.0)\n","Installing collected packages: regex, nltk\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.6.5 regex-2022.4.24\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers\n","!pip install rouge_metric\n","!pip install nltk==3.6.5\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"fv9NCrRce9gB","executionInfo":{"status":"ok","timestamp":1653163486614,"user_tz":-120,"elapsed":10066,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["import torch\n","import evaluation\n","import argparse\n","import qrdatasets\n","import models\n","from utils import *\n","import random\n","import t5small\n","import t5base\n","import os\n","import nltk"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"DaaIkT7VfB9r","executionInfo":{"status":"ok","timestamp":1653163486617,"user_tz":-120,"elapsed":20,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["def get_arguments():\n","    parser = argparse.ArgumentParser(description = '')\n","    parser.add_argument('--action', default='train',choices=['eval', 'pre-eval', 'train'],\n","                        help='\"pre-eval\" evaluates the model on dev-sets, while \"eval\" evaluates on test sets.')\n","    parser.add_argument('--dataset_name', default='mixed',choices=['canard', 'coqar', 'mixed'],\n","                        help='Use this argument only when training. With \"mixed\", a mix of CANARD and COQAR is used.')\n","    parser.add_argument('--model_path', type=str, default='',\n","                        help='Only for eval/pre-eval. Path of the model to evaluate.')\n","    # parameters\n","    parser.add_argument('--epochs', default=3, type=int, help='only for training')\n","    parser.add_argument('--learning_rate', default=0.00005, type=float, help='only for training')\n","    parser.add_argument('--history_size', default=3, type=int, help='only for training')  # not only for training\n","    parser.add_argument('--batch_size', default=16, type=int)\n","    parser.add_argument('--dropout_rate', default=0.1, type=float, help='only for training')\n","    parser.add_argument('--include_story', default=True, help='include_story')\n","    parser.add_argument('--model_size', default='small', help='model_size')\n","    parser.add_argument('--smoke_test', dest='smoke_test', action='store_true', help='only for training')\n","    parser.set_defaults(smoke_test=False)\n","    args = parser.parse_args([])\n","    return args"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1653163487016,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"6F4IP3h56h7F","outputId":"924526d9-397a-4659-b831-dae8c85eeee2"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["random.seed(63254)\n","args = get_arguments()\n","\n","# default parameters\n","hparams = {\n","    'epochs' : 3,\n","    'learning_rate' : 0.00005,\n","    'batch_size' : 16,\n","    'weight_decay' : 0.0,\n","    'history_size' : 20,\n","    'dropout_rate' : 0.1,\n","    'include_story' : True,\n","    'model_size' : 'small'\n","}\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wGzMXKTcyBcz","executionInfo":{"status":"ok","timestamp":1653163487017,"user_tz":-120,"elapsed":20,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["# overrides default params\n","if args.batch_size != None:\n","    hparams['batch_size'] = args.batch_size\n","if args.dropout_rate != None:\n","    hparams['dropout_rate'] = args.dropout_rate\n","if args.learning_rate != None:\n","    hparams['learning_rate'] = args.learning_rate\n","if args.history_size != None:\n","    hparams['history_size'] = args.history_size\n","if args.model_size != None:\n","    hparams['model_size'] = args.model_size"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1653163487018,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"xjEnF5SNyJdL","outputId":"027b2c08-c620-46cc-d803-65a3b91d457f"},"outputs":[{"output_type":"stream","name":"stdout","text":["current t5 model: <module 't5small' from './mydata/MyDrive/COQAR/rewriting/t5small.py'>\n"]}],"source":["t5_models = [t5small, t5base]\n","\n","if hparams['model_size'] == 'small':\n","  t5_model = t5_models[0]\n","elif hparams['model_size'] == 'base':\n","  t5_model = t5_models[1]\n","\n","print('current t5 model:',t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgnG9xQW6h9y"},"outputs":[],"source":["# train the model\n","\n","### check model.train_dev_loop stop condition, should use the second or third last epoch as trained model\n","args.action = 'train'\n","model_epoch_path = './mydata/MyDrive/COQAR/trained_models/training0/epoch1'\n","if args.action == 'train':\n","    dir_path = create_and_get_dir('./mydata/MyDrive/COQAR/trained_models', 'training')\n","    \n","    models.train_dev_loop(args, hparams, log_dir_path = dir_path, t5_model = t5_model, model_epoch_path = model_epoch_path)\n","\n","    # models.train_dev_loop(args, hparams, log_dir_path = dir_path, t5_model = t5_model)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567011,"status":"ok","timestamp":1653173093435,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"zTmMLRQAyMxT","outputId":"803da62a-dec7-4412-85d1-fed82200ad50"},"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["coqar: {'BLEU': 0.40307622255484515, 'ROUGE': 0.4293164514423723, 'METEOR': 0.598848714608091}\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["canard: {'BLEU': 0.47249881382811804, 'ROUGE': 0.7052649439518603, 'METEOR': 0.7041165688362422}\n"]}],"source":["# evaluate the model\n","args.action = 'eval'\n","args.model_path = './mydata/MyDrive/COQAR/trained_models/training1/epoch11'\n","\n","\n","if args.action in ['eval', 'pre-eval']:\n","    \n","    model = torch.load(args.model_path)\n","    if args.action == 'eval':\n","        \n","        coqar = qrdatasets.get_coqar_test_set(hparams['include_story'])\n","        canard = qrdatasets.get_canard_test_set(hparams['include_story'])\n","\n","    if args.action == 'pre-eval':\n","    \n","        _, coqar = qrdatasets.get_coqar_train_and_dev_sets(hparams['include_story'])\n","        canard = qrdatasets.get_canard_dev_set(hparams['include_story'])\n","\n","    # data is formatted now\n","    for data, dataset_name in [(coqar, 'coqar'), (canard, 'canard')]:\n","        predictions = evaluation.generate_predictions(\n","            model = model,\n","            data = data,\n","            # make dataset in the same way as training\n","            dataset_maker = t5_model.make_dataset,\n","            output_tokenizer = t5_model.get_output_tokenizer(),\n","            hparams = hparams)\n","\n","        print(f\"{dataset_name}: {evaluation.evaluate(predictions, data['references'])}\")\n","        #evaluation.display_examples(predictions, data['references'], data['input'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vACczM_FFPeH"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ErckMs8FPgu"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rn1elLwdFPn3"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BolGaiboFPqK"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BhcnyVoPFPsr"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pXtVk4CZFPvD"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDjElPkFFPxi"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpH_nIGjFP0B"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nri3Ft6FP2m"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"T5_question_rewriting.ipynb","provenance":[],"authorship_tag":"ABX9TyPgNM5/USACE3mR4GNG+kh4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}