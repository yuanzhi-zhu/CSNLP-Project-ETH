{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms9WY7esN3OP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655473663668,"user_tz":-120,"elapsed":1781,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"7952601c-50ba-40fe-fcce-6aca186a92dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at ./mydata; to attempt to forcibly remount, call drive.mount(\"./mydata\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('./mydata')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgEda4XUdZOp"},"outputs":[],"source":["import sys\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/T5_model_COQAR')\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/T5_model_COQAR/rewriting')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jTW4y6iLdlPG"},"outputs":[],"source":["!pip install transformers==4.19.2\n","!pip install rouge_metric\n","!pip install nltk==3.6.5\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv9NCrRce9gB"},"outputs":[],"source":["import torch\n","import evaluation\n","import argparse\n","import qrdatasets\n","import models\n","from utils import *\n","import random\n","import t5small\n","import t5base\n","import os\n","import nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DaaIkT7VfB9r"},"outputs":[],"source":["def get_arguments():\n","    parser = argparse.ArgumentParser(description = '')\n","    parser.add_argument('--action', default='train',choices=['eval', 'pre-eval', 'train'],\n","                        help='\"pre-eval\" evaluates the model on dev-sets, while \"eval\" evaluates on test sets.')\n","    parser.add_argument('--dataset_name', default='mixed',choices=['canard', 'coqar', 'mixed'],\n","                        help='Use this argument only when training. With \"mixed\", a mix of CANARD and COQAR is used.')\n","    parser.add_argument('--model_path', type=str, default='',\n","                        help='Only for eval/pre-eval. Path of the model to evaluate.')\n","    # parameters\n","    parser.add_argument('--epochs', default=3, type=int, help='only for training')\n","    parser.add_argument('--learning_rate', default=0.00005, type=float, help='only for training')\n","    parser.add_argument('--history_size', default=3, type=int, help='only for training')  # not only for training\n","    parser.add_argument('--batch_size', default=16, type=int)\n","    parser.add_argument('--dropout_rate', default=0.1, type=float, help='only for training')\n","    parser.add_argument('--include_story', default=True, help='include_story')\n","    parser.add_argument('--model_size', default='small', help='model_size')\n","    parser.add_argument('--smoke_test', dest='smoke_test', action='store_true', help='only for training')\n","    parser.set_defaults(smoke_test=False)\n","    args = parser.parse_args([])\n","    return args"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1655473724649,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"6F4IP3h56h7F","outputId":"38a0c63e-da58-409c-ee92-d414e5253e45"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["random.seed(63254)\n","args = get_arguments()\n","\n","# default parameters\n","hparams = {\n","    'epochs' : 3,\n","    'learning_rate' : 0.00005,\n","    'batch_size' : 16,\n","    'weight_decay' : 0.0,\n","    'history_size' : 20,\n","    'dropout_rate' : 0.1,\n","    'include_story' : True,\n","    'model_size' : 'small'\n","}\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGzMXKTcyBcz"},"outputs":[],"source":["# overrides default params\n","if args.batch_size != None:\n","    hparams['batch_size'] = args.batch_size\n","if args.dropout_rate != None:\n","    hparams['dropout_rate'] = args.dropout_rate\n","if args.learning_rate != None:\n","    hparams['learning_rate'] = args.learning_rate\n","if args.history_size != None:\n","    hparams['history_size'] = args.history_size\n","if args.model_size != None:\n","    hparams['model_size'] = args.model_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222,"status":"ok","timestamp":1655473727658,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"xjEnF5SNyJdL","outputId":"bf978fb5-0d95-4881-abb5-405011d8c98d"},"outputs":[{"output_type":"stream","name":"stdout","text":["current t5 model: <module 't5small' from './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/rewriting/t5small.py'>\n"]}],"source":["t5_models = [t5small, t5base]\n","\n","if hparams['model_size'] == 'small':\n","  t5_model = t5_models[0]\n","elif hparams['model_size'] == 'base':\n","  t5_model = t5_models[1]\n","\n","print('current t5 model:',t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgnG9xQW6h9y"},"outputs":[],"source":["# train the model\n","\n","### check model.train_dev_loop stop condition, should use the second or third last epoch as trained model\n","args.action = 'train'\n","# continue training\n","model_epoch_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_small_with_story_batch16_hist_3_mixed/epoch10'\n","if args.action == 'train':\n","    dir_path = create_and_get_dir('./mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models', 'training')\n","    \n","    models.train_dev_loop(args, hparams, log_dir_path = dir_path, t5_model = t5_model, model_epoch_path = model_epoch_path)\n","\n","    # models.train_dev_loop(args, hparams, log_dir_path = dir_path, t5_model = t5_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":508362,"status":"ok","timestamp":1655474292285,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"zTmMLRQAyMxT","outputId":"9c30a441-9b4c-4b6c-fc52-cf9cc7be2fe2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["coqar: {'BLEU': 0.40389581211520253, 'ROUGE': 0.4279942932021437, 'METEOR': 0.597503882764309}\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["canard: {'BLEU': 0.4756776761410914, 'ROUGE': 0.7074058007706036, 'METEOR': 0.7075073407988256}\n"]}],"source":["# evaluate the model\n","\n","args.action = 'eval'\n","args.model_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_small_with_story_batch16_hist_3_mixed/epoch10'\n","\n","if args.action in ['eval', 'pre-eval']:\n","    \n","    model = torch.load(args.model_path)\n","    if args.action == 'eval':\n","        \n","        coqar = qrdatasets.get_coqar_test_set(hparams['include_story'])\n","        canard = qrdatasets.get_canard_test_set(hparams['include_story'])\n","\n","    if args.action == 'pre-eval':\n","    \n","        _, coqar = qrdatasets.get_coqar_train_and_dev_sets(hparams['include_story'])\n","        canard = qrdatasets.get_canard_dev_set(hparams['include_story'])\n","\n","    # data is formatted now\n","    for data, dataset_name in [(coqar, 'coqar'), (canard, 'canard')]:\n","        predictions = evaluation.generate_predictions(\n","            model = model,\n","            data = data,\n","            # make dataset in the same way as training\n","            dataset_maker = t5_model.make_dataset,\n","            output_tokenizer = t5_model.get_output_tokenizer(),\n","            hparams = hparams)\n","\n","        print(f\"{dataset_name}: {evaluation.evaluate(predictions, data['references'])}\")\n","        #evaluation.display_examples(predictions, data['references'], data['input'])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"T5_question_rewriting.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}