{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JfgX6lC-CeEN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657209824980,"user_tz":-120,"elapsed":15267,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"def1acb1-35ed-42a8-e4a3-3a3aa468144e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.19.2 in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (3.7.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (0.12.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (4.64.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (4.11.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (0.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.2) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.2) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.2) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.2) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.2) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: rouge_metric in /usr/local/lib/python3.7/dist-packages (1.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk==3.6.5 in /usr/local/lib/python3.7/dist-packages (3.6.5)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (1.1.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.5) (4.64.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Drive already mounted at ./mydata; to attempt to forcibly remount, call drive.mount(\"./mydata\", force_remount=True).\n"]}],"source":["!pip install transformers==4.19.2\n","!pip install rouge_metric\n","!pip install nltk==3.6.5\n","!pip install sentencepiece\n","from google.colab import drive\n","drive.mount('./mydata')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wyzGkzsuHNAA","executionInfo":{"status":"ok","timestamp":1657209824981,"user_tz":-120,"elapsed":14,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["import sys\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/Bert_model_COQA')\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/T5_model_COQAR')\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/T5_model_COQAR/rewriting')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"UZAJcRiiEZqp","executionInfo":{"status":"ok","timestamp":1657209836069,"user_tz":-120,"elapsed":11100,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["import collections\n","import glob\n","import os\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tqdm, trange\n","from transformers import (AdamW, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, BertTokenizer, BertModel, BertConfig)\n","from processors.coqa import Extract_Features, Processor, Result\n","from processors.evaluate import CoQAEvaluator, parse_args\n","from processors.Bert_model import BertBaseUncasedModel, BertBaseUncasedModel_with_T5, load_dataset, Write_predictions, Write_predictions_with_T5\n","\n","#from transformers import BertModel, BertPreTrainedModel\n","\n","import csv\n","import numpy as np\n","\n","import evaluation\n","import argparse\n","import qrdatasets\n","import models\n","from utils import *\n","import random\n","import t5small\n","import t5base\n","import nltk\n","\n","import config\n","import json\n","\n","# CoQA dataset file\n","train_file=\"coqa-train-v1.0.json\"\n","predict_file=\"coqa-dev-v1.0.json\"\n","cur_path = os.getcwd()\n","output_directory = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models\"\n","input_dir = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data\"\n","# can use either BERT base or BERT large\n","pretrained_model=\"bert-base-uncased\"\n","# pretrained_model=\"bert-large-uncased\"\n","# it's better to fine-tune Bert-base for 4 epoches than only one\n","epochs = 2\n","evaluation_batch_size=1\n","train_batch_size=2"]},{"cell_type":"markdown","metadata":{"id":"jvCeeKjL1PBp"},"source":["### create now dataset (json file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyM0goV04hKB"},"outputs":[],"source":["### Load two fine-tuned models, but with diffetent load methods\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# load bert\n","# bert_path = './mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_from_original_Surya_epoch4'\n","# bert_model = BertBaseUncasedModel.from_pretrained(bert_path) \n","# bert_tokenizer = BertTokenizer.from_pretrained(bert_path, do_lower_case=True)\n","# bert_model.to(device)\n","\n","# load t5\n","# t5_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_small_with_story_batch16_hist_3_mixed/epoch10'\n","t5_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_base_with_story_batch4_hist_20/epoch6.zip'\n","\n","t5_model = torch.load(t5_path)\n","# t5_input_tokenizer = t5small.get_input_tokenizer()\n","# t5_output_tokenizer = t5small.get_output_tokenizer()\n","t5_input_tokenizer = t5base.get_input_tokenizer()\n","t5_output_tokenizer = t5base.get_output_tokenizer()\n","t5_model.to(device)\n","\n","pass"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EVlsaahMN_EZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657209845656,"user_tz":-120,"elapsed":293,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"1847b14d-822d-4a03-9b79-49f6d13343a4"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}],"source":["# default parameters for T5\n","hparams = {\n","    'epochs' : 2,\n","    'learning_rate' : 0.00005,\n","    'batch_size' : 4,\n","    'weight_decay' : 0.0,\n","    'history_size' : 3,\n","    'dropout_rate' : 0.1,\n","    'include_story' : True,\n","    'model_size' : 'small'\n","}\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"cSwK3c3Rp3uo","executionInfo":{"status":"ok","timestamp":1657209847287,"user_tz":-120,"elapsed":306,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["def make_t5_dataset(input_dir,file_type='train',t5_type='base',train_file=train_file):\n","    ### open the COQA dataset\n","    if file_type == 'train':\n","        # training dataset\n","        with open(os.path.join(input_dir, train_file), \"r\", encoding=\"utf-8\") as reader:\n","            input_data = json.load(reader)\n","    elif file_type == 'dev':\n","        # dev dataset\n","        with open(os.path.join(input_dir, predict_file), \"r\", encoding=\"utf-8\") as reader:\n","            input_data = json.load(reader)\n","    else:\n","        raise Exception(\"must specify a file type: train/dev\")\n","        pass\n","    \n","    # create empty dictionary\n","    t5_data = {'input':[], 'references':[], 'context':[]}\n","    # create dataset for T5\n","    for input_d in input_data[\"data\"]:\n","        questions = []\n","        assert len(input_d['questions']) == len(input_d['answers'])\n","        for id_q in range(len(input_d['questions'])):\n","            curr_question = input_d['questions'][id_q]['input_text']\n","            if '?' not in curr_question:\n","                if len(curr_question) == 0:\n","                    pass\n","                # some question in statement form end with '.'\n","                elif curr_question[-1] in ['.']:\n","                    if curr_question[-2:] == '/.':\n","                        curr_question = curr_question[:-2] + '?'\n","                    elif ('True or False' in curr_question) or ('Name' in curr_question):\n","                        pass\n","                    else:\n","                        # not worth to deal with such small portion of data\n","                        pass\n","                elif curr_question[-1] in ['/']:\n","                    curr_question = curr_question[:-1] + '?'\n","                else:\n","                    curr_question += '?'\n","            if id_q == 0:\n","                questions.append(curr_question)\n","            else:\n","                questions.append(input_d['answers'][id_q-1]['input_text'])\n","                questions.append(curr_question)\n","            t5_data['input'].append(questions.copy())\n","            t5_data['references'].append([''])\n","            t5_data['context'].append(input_d['story'])\n","\n","    # T5 make dataset\n","    if t5_type == 'base':\n","        dataset = t5base.make_dataset(t5_data, hparams, cuda = True)\n","    elif t5_type == 'small':\n","        dataset = t5base.make_dataset(t5_data, hparams, cuda = True)\n","    else:\n","        raise Exception(\"must specify a t5 model type: base/small\")\n","    \n","    return dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1o7NxaOY6VcT"},"outputs":[],"source":["# get rewritten answers from T5\n","\n","def generate_new_dataset(input_dir,file_type='train',t5_type='base',t5_model=t5_model,method='append'):\n","    ### open the COQA dataset\n","    if file_type == 'train':\n","        # training dataset\n","        with open(os.path.join(input_dir, train_file), \"r\", encoding=\"utf-8\") as reader:\n","            input_data = json.load(reader)\n","    elif file_type == 'dev':\n","        # dev dataset\n","        with open(os.path.join(input_dir, predict_file), \"r\", encoding=\"utf-8\") as reader:\n","            input_data = json.load(reader)\n","    else:\n","        raise Exception(\"must specify a file type: train/dev\")\n","        pass\n","        \n","    if 'repeat' not in method:\n","        # get dataset\n","        dataset = make_t5_dataset(input_dir,file_type=file_type,t5_type=t5_type,train_file=train_file)\n","\n","        ### generate rewritten questions\n","        loader = DataLoader(dataset=dataset, batch_size=hparams['batch_size'])\n","        t5_model.cuda()\n","        t5_model.train(False)\n","        rewritten_qs = []\n","        for dic in tqdm(loader, desc=\"Generating rewritten questions\"):\n","            output = t5_model.generate(input_ids = dic['input_ids'], attention_mask = dic['attention_mask'])\n","            pred = t5_output_tokenizer.batch_decode(output, skip_special_tokens = True)\n","            rewritten_qs += pred\n","\n","    ### Create new training/dev dataset json file for Bert\n","    # append or replace with the generated question \n","    count = 0\n","    for story_id in range(len(input_data[\"data\"])):\n","        for question_id in range(len(input_data[\"data\"][story_id]['questions'])):\n","            # if the rewritten question from T5 is failed, we use the original question.\n","            # also clean the question data\n","            curr_question = input_data[\"data\"][story_id]['questions'][question_id]['input_text']\n","            if '?' not in curr_question:\n","                if len(curr_question) == 0:\n","                    pass\n","                # some question in statement form end with '.'\n","                elif curr_question[-1] in ['.']:\n","                    if curr_question[-2:] == '/.':\n","                        curr_question = curr_question[:-2] + '?'\n","                    elif ('True or False' in curr_question) or ('Name' in curr_question):\n","                        pass\n","                    else:\n","                        # not worth to deal with such small portion of data\n","                        pass\n","                elif curr_question[-1] in ['/']:\n","                    curr_question = curr_question[:-1] + '?'\n","                else:\n","                    curr_question += '?'\n","\n","            if 'repeat' not in method:\n","                if len(rewritten_qs[count]) < 2:\n","                    pass\n","                # for failed rewritten questions(those not even questions)\n","                elif rewritten_qs[count][-1] != '?':\n","                    rewritten_qs[count] = curr_question\n","            if 'append' in method:\n","                # append the rewritten question\n","                input_data[\"data\"][story_id]['questions'][question_id]['input_text'] = curr_question + (' '+rewritten_qs[count])\n","            elif 'replace' in method:\n","                # replace with the rewritten question\n","                input_data[\"data\"][story_id]['questions'][question_id]['input_text'] = rewritten_qs[count]\n","            elif 'repeat' in method:\n","                # repeat the curent question twice for comparison\n","                input_data[\"data\"][story_id]['questions'][question_id]['input_text'] = curr_question + (' '+curr_question)\n","            else:\n","                raise Exception(\"must specify a method: append/replace\")\n","                pass\n","            count += 1\n","\n","    # save as new dataset json file\n","    file_name = 'coqa-{}-v1.0-{}_with_T5.json'.format(file_type,method)\n","    # with open(os.path.join( input_dir, 'coqa-dev-v1.0-with_T5.json'), 'w', encoding=\"utf-8\") as outfile:\n","    with open(os.path.join(input_dir, file_name), 'w', encoding=\"utf-8\") as outfile:\n","        json.dump(input_data, outfile)\n","\n","generate_new_dataset(input_dir,file_type='dev',t5_type='base',t5_model=t5_model,method='append_v3')"]},{"cell_type":"markdown","metadata":{"id":"fFtnkFKgvWXh"},"source":["### train bert with t5 embedding"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"lymNPhfWl7-E","executionInfo":{"status":"ok","timestamp":1657209858062,"user_tz":-120,"elapsed":525,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[],"source":["def train_bert_with_t5(bert_model, t5_model, bert_tokenizer, bert_dataset, t5_dataset, device, pretrained_model, t5_pooled=False, epochs_trained=0, start_iter=0, start_total_loss=0, batch_size=2, save_criteria=None):\n","    save_flag = True\n","\n","    bert_train_sampler = SequentialSampler(bert_dataset) \n","    bert_dataloader = DataLoader(bert_dataset, sampler=bert_train_sampler, batch_size=batch_size)\n","    t5_dataloader = DataLoader(dataset=t5_dataset, batch_size=batch_size)\n","    t_total = len(bert_dataloader) // 1 * epochs\n","\n","    # Preparing optimizer and scheduler\n","    optimizer_parameters = [{\"params\": [p for n, p in bert_model.named_parameters() if not any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])],\"weight_decay\": 0.01,},{\"params\": [p for n, p in bert_model.named_parameters() if any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])], \"weight_decay\": 0.0}]\n","    optimizer = AdamW(optimizer_parameters,lr=1e-5, eps=1e-8)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2000, num_training_steps=t_total)\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if os.path.isfile(os.path.join(pretrained_model, \"optimizer.pt\")) and os.path.isfile(os.path.join(pretrained_model, \"scheduler.pt\")):\n","        optimizer.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"scheduler.pt\")))\n","\n","    counter = 1\n","    # epochs_trained = 0\n","    train_loss, loss = start_total_loss, 0.0\n","    bert_model.zero_grad()\n","    iterator = trange(0, int(epochs), desc=\"Epoch\", disable=False)\n","    for epoch_id in iterator:\n","        epoch_iterator = tqdm(zip(bert_dataloader,t5_dataloader), desc=\"Iteration\", disable=True)\n","        for i,batch in enumerate(epoch_iterator):\n","            # skip the first few iterations\n","            if (epoch_id < epochs_trained) or ((epoch_id == epochs_trained) and (i<=start_iter)):\n","                counter += 1\n","                continue\n","            batch_bert, batch_t5 = batch\n","            # model.encoder(input_ids=s, attention_mask=attn, return_dict=True)\n","            # pooled_sentence = output.last_hidden_state # shape is [batch_size, seq_len, hidden_size]\n","            # # pooled_sentence will represent the embeddings for each word in the sentence\n","            # # you need to sum/average the pooled_sentence\n","            # pooled_sentence = torch.mean(pooled_sentence, dim=1)\n","            batch_t5['input_ids'] = batch_t5['input_ids'].to(device)\n","            batch_t5['attention_mask'] = batch_t5['attention_mask'].to(device)\n","            t5_embdeding = t5_model.encoder(input_ids = batch_t5['input_ids'], attention_mask = batch_t5['attention_mask'], return_dict=False)\n","            bert_model.train()\n","            batch_bert = tuple(t.to(device) for t in batch_bert)\n","            # inputs = { \"input_ids\": batch_bert[0],\"token_type_ids\": batch_bert[1], \"attention_mask\": batch_bert[2],\"start_positions\": batch_bert[3],\"end_positions\": batch_bert[4],\"rational_mask\": batch_bert[5],\"cls_idx\": batch_bert[6]}\n","            # loss = bert_model(**inputs)\n","            loss = bert_model(batch_bert[0],t5_embdeding,batch_t5,t5_pooled,token_type_ids=batch_bert[1],attention_mask=batch_bert[2],\\\n","                              start_positions=batch_bert[3],end_positions=batch_bert[4],rational_mask=batch_bert[5],cls_idx=batch_bert[6],head_mask=None)\n","            loss.backward()\n","            train_loss += loss.item()\n","\n","            #   optimizing training parameters\n","            if (i + 1) % 1 == 0:\n","                optimizer.step()\n","                scheduler.step()  \n","                bert_model.zero_grad()\n","                counter += 1\n","                #   Saving model weights every 1000 iterations\n","                if counter % 1000 == 0:\n","                    output_dir = os.path.join(output_directory, \"model_weights\"+str(epochs_trained))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    model_to_save = bert_model.module if hasattr(bert_model, \"module\") else bert_model\n","                    model_to_save.save_pretrained(output_dir)\n","                    bert_tokenizer.save_pretrained(output_dir)\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            if (i+1) % 1000 == 0:\n","                print('iter: {}, loss: {}'.format(i,train_loss/counter))\n","\n","            if save_criteria and save_flag and ((train_loss/counter)<save_criteria):\n","                save_flag = False\n","                variant_name = 'Bert_with_T5_embdding_cond'\n","\n","                #   create output directory for model parameters and to write predictions\n","                if not os.path.exists(output_directory+'/'+variant_name) :\n","                    os.makedirs(output_directory+'/'+variant_name)\n","                            \n","                model_to_save = bert_model.module if hasattr(bert_model, \"module\") else bert_model\n","                model_to_save.save_pretrained(output_directory+'/'+variant_name)\n","                bert_tokenizer.save_pretrained(output_directory+'/'+variant_name)\n","                return train_loss/counter\n","\n","    return train_loss/counter"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"y8kuWh347W1-","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["182eb850052e4d57ab0f03f6a1ff67de","902ec0c1258c40319dc8781ac9617fdc","116bde7fceb746d98ad7f47a2423a37c","6a4390413e16481a82333c1644ffdd6e","b8e3a4c15bd8449a987e319c36d38e79","7f47cddc3684492faef83d7bad08db99","92f113b09e3b46a6b6544ca728db19d1","17c00fc5a8854a42a33c15054ecb3c4d","c6c5fedbddf143718033648a45ad9220","19819d5b5ca74d6788bdad74a2e5b844","41abebf76f1343dc97d7197361af8f6e","9b60426ca9c74d0db109617acd6fafee","2dd593bf1294404395b64fa6d82b664b","8be50df8307349729f05772880e5ef2e","06569de5d65641579bf0d6457e5d97fb","51a775c3793545cc9256f0206afffbda","3444b35d445243fcadd6dc9cc0ae5a7a","ab56edbea9054792bff0a5484507265b","d091e0f0607a44989354707fe9c87173","39090303e3fd4f208932ecace766399e","88d5fbc30c974014a988df2a298c34bd","7d96da108fad408b8d9f8f78ce4b8323","65e8c47bce5043aca9b3765ee6dff989","df5c88568c994d24bb7598b73390231f","1f98c40b9de24b1695fe092192598f2a","9b50714d54ca4fe1b194fda116b18e37","33eadd1928084f74ace1bf8975ba0b46","a3bb639455244b76a86b377c5338d1c3","2271bbabc2794fee893eec76e9d83818","12c4470f00ca48c4832ec507a27f6b26","c76f4d5cc7914439a5c0d288bd73ab8b","b5d8a18596454be8bfd65d5f81345927","2c9c7cf4016e45e2959a721b369ac4d5","42dad6122bb74ed0991b075672ecf688","437b631280f4469e9b8ef3ff3961c161","4de21ca23aad424ca414be9c27d61ef6","95dfea02ebdf4228aed7c702d30f9a68","b1269fe4657a4ed4a5cccd0bc916d30c","dbd8361f446a407e95ea448dbd4bf554","7c237bcfe60d42fc9b2d3fdf93878d6a","f59736e7f13a40a0a08b6196921ac2ff","0f058fe7d6544248b681b33a49de5626","9656305b51294a1a9415559b6c8bda45","7e4861065db04e488f32d7995392061d"]},"outputId":"2c7943a4-5f65-4e88-8ba0-d11d4e925543","executionInfo":{"status":"ok","timestamp":1657201393493,"user_tz":-120,"elapsed":53703516,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182eb850052e4d57ab0f03f6a1ff67de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b60426ca9c74d0db109617acd6fafee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65e8c47bce5043aca9b3765ee6dff989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42dad6122bb74ed0991b075672ecf688"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertBaseUncasedModel_with_T5: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertBaseUncasedModel_with_T5 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertBaseUncasedModel_with_T5 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertBaseUncasedModel_with_T5 were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['unk_layers.linears.1.bias', 'attention_layers.linears.1.weight', 'yn_layers.linears.0.weight', 'logits_layers.linears.1.weight', 'yn_layers.linears.0.bias', 'rational_layers.linears.1.weight', 'yn_layers.linears.1.weight', 'logits_layers.linears.1.bias', 'rational_layers.linears.1.bias', 'logits_layers.linears.0.weight', 'unk_layers.linears.1.weight', 'unk_layers.linears.0.weight', 'attention_layers.linears.0.weight', 'yn_layers.linears.1.bias', 'unk_layers.linears.0.bias', 'attention_layers.linears.1.bias', 'logits_layers.linears.0.bias', 'rational_layers.linears.0.bias', 'attention_layers.linears.0.bias', 'rational_layers.linears.0.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 5.486859989938858\n","iter: 1999, loss: 4.753607458305322\n","iter: 2999, loss: 4.201126125379345\n","iter: 3999, loss: 3.8192279854704108\n","iter: 4999, loss: 3.5686778184470835\n","iter: 5999, loss: 3.372409662055415\n","iter: 6999, loss: 3.2319617550937254\n","iter: 7999, loss: 3.119186821406317\n","iter: 8999, loss: 3.021361992759289\n","iter: 9999, loss: 2.947090112462539\n","iter: 10999, loss: 2.874695964008614\n","iter: 11999, loss: 2.8178673969777734\n","iter: 12999, loss: 2.75632369275295\n","iter: 13999, loss: 2.711875973024277\n","iter: 14999, loss: 2.6703872270563798\n","iter: 15999, loss: 2.635548570434484\n","iter: 16999, loss: 2.5998644132881914\n","iter: 17999, loss: 2.570510077396671\n","iter: 18999, loss: 2.53962521626975\n","iter: 19999, loss: 2.5179892607768486\n","iter: 20999, loss: 2.495632609299334\n","iter: 21999, loss: 2.4744654040295595\n","iter: 22999, loss: 2.454104571533488\n","iter: 23999, loss: 2.4388994706166804\n","iter: 24999, loss: 2.4219676967941868\n","iter: 25999, loss: 2.404442399628862\n","iter: 26999, loss: 2.385971111524858\n","iter: 27999, loss: 2.3678963815754837\n","iter: 28999, loss: 2.3568076047812774\n","iter: 29999, loss: 2.3414815101250284\n","iter: 30999, loss: 2.3281374949088076\n","iter: 31999, loss: 2.31050475100268\n","iter: 32999, loss: 2.2988931035063525\n","iter: 33999, loss: 2.2852659016341414\n","iter: 34999, loss: 2.2715194551613758\n","iter: 35999, loss: 2.259420658700326\n","iter: 36999, loss: 2.2503410756657223\n","iter: 37999, loss: 2.2384389058407548\n","iter: 38999, loss: 2.2274865998476923\n","iter: 39999, loss: 2.215162742748208\n","iter: 40999, loss: 2.207886739593289\n","iter: 41999, loss: 2.1991212284088313\n","iter: 42999, loss: 2.189415041654287\n","iter: 43999, loss: 2.181392271013876\n","iter: 44999, loss: 2.174371062562806\n","iter: 45999, loss: 2.1678541951104378\n","iter: 46999, loss: 2.160411663377341\n","iter: 47999, loss: 2.152342826041812\n","iter: 48999, loss: 2.1493444486229927\n","iter: 49999, loss: 2.140992983139833\n","iter: 50999, loss: 2.1335722343468553\n","iter: 51999, loss: 2.1246907581628536\n","iter: 52999, loss: 2.1190575017854947\n","iter: 53999, loss: 2.112960214937929\n","iter: 54999, loss: 2.1089837270498424\n","iter: 55999, loss: 2.1026452255334083\n","iter: 56999, loss: 2.0975707041967575\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 1/2 [7:24:12<7:24:12, 26652.50s/it]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 2.0866245107399295\n","iter: 1999, loss: 2.0801539724235205\n","iter: 2999, loss: 2.074297689679974\n","iter: 3999, loss: 2.065809209649494\n","iter: 4999, loss: 2.058095580037011\n","iter: 5999, loss: 2.049800467169048\n","iter: 6999, loss: 2.041416174390211\n","iter: 7999, loss: 2.0337118963546574\n","iter: 8999, loss: 2.025173434316342\n","iter: 9999, loss: 2.01749550983261\n","iter: 10999, loss: 2.0089170938594307\n","iter: 11999, loss: 2.00121487435743\n","iter: 12999, loss: 1.9912737813517964\n","iter: 13999, loss: 1.9827952360456673\n","iter: 14999, loss: 1.9748220115193666\n","iter: 15999, loss: 1.967216445131775\n","iter: 16999, loss: 1.9595122650745371\n","iter: 17999, loss: 1.9524295410340062\n","iter: 18999, loss: 1.9448329111133118\n","iter: 19999, loss: 1.9386545601324068\n","iter: 20999, loss: 1.9320863927424359\n","iter: 21999, loss: 1.9259368697209807\n","iter: 22999, loss: 1.9194505496086267\n","iter: 23999, loss: 1.9139686889627456\n","iter: 24999, loss: 1.908081156859474\n","iter: 25999, loss: 1.9018434391766925\n","iter: 26999, loss: 1.8950574648597804\n","iter: 27999, loss: 1.8883074896460215\n","iter: 28999, loss: 1.883269177461978\n","iter: 29999, loss: 1.8771887701337013\n","iter: 30999, loss: 1.8713869777381984\n","iter: 31999, loss: 1.8644368731956804\n","iter: 32999, loss: 1.8593321777568852\n","iter: 33999, loss: 1.8528992945564389\n","iter: 34999, loss: 1.8466048516887221\n","iter: 35999, loss: 1.8407434076653144\n","iter: 36999, loss: 1.8357566935729865\n","iter: 37999, loss: 1.829716073888124\n","iter: 38999, loss: 1.8242467858144702\n","iter: 39999, loss: 1.8185546862727586\n","iter: 40999, loss: 1.8140629279818734\n","iter: 41999, loss: 1.8090900606025915\n","iter: 42999, loss: 1.8041799080637624\n","iter: 43999, loss: 1.79985100614498\n","iter: 44999, loss: 1.7955794156851665\n","iter: 45999, loss: 1.7916926010408087\n","iter: 46999, loss: 1.787410958850551\n","iter: 47999, loss: 1.783044342869766\n","iter: 48999, loss: 1.7808281946416242\n","iter: 49999, loss: 1.7759566101993025\n","iter: 50999, loss: 1.7717686716478216\n","iter: 51999, loss: 1.7669798078250778\n","iter: 52999, loss: 1.763595680077362\n","iter: 53999, loss: 1.7596777687217606\n","iter: 54999, loss: 1.7568875016907124\n","iter: 55999, loss: 1.7532572017465238\n","iter: 56999, loss: 1.7503561653944648\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 2/2 [14:49:02<00:00, 26671.27s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["1.747721705783295"]},"metadata":{},"execution_count":7}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","method = 'append'\n","epochs = 4\n","start_iter = 0\n","epochs_trained = 3\n","start_total_loss = 0  #1.747721705783295 * (56999*2)\n","save_criteria = None\n","t5_pooled = True\n","\n","pretrained_model = './mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_poled_embedding_epoch2_batch2/'\n","# pretrained_model=\"bert-base-uncased\"\n","\n","## load raw model\n","# t5 \n","t5_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_base_with_story_batch4_hist_20/epoch6.zip'\n","t5_model = torch.load(t5_path)\n","t5_input_tokenizer = t5base.get_input_tokenizer()   # or t5small \n","t5_output_tokenizer = t5base.get_output_tokenizer()\n","t5_model.to(device)\n","t5_model.train(False)\n","# bert\n","config = BertConfig.from_pretrained(pretrained_model, return_dict=False)\n","bert_tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n","bert_model = BertBaseUncasedModel_with_T5.from_pretrained(pretrained_model, from_tf=bool(\".ckpt\" in pretrained_model), config=config,cache_dir=None,)\n","bert_model.to(device)\n","\n","## get datasets\n","t5_dataset = make_t5_dataset(input_dir,file_type='train',t5_type='base',train_file=train_file)\n","# cache_file_name = 'bert-base-uncased_train_with_T5_{}_v3.2'.format(method)\n","# train_file_name = 'coqa-train-v1.0-{}_v3_with_T5.json'.format(method)\n","cache_file_name = 'bert-base-uncased_train'\n","# cache_file_name = 'bert-base-uncased_train_with_T5_append_v3_all'\n","train_file_name = 'coqa-train-v1.0.json'\n","\n","if cache_file_name is not None:\n","    cache_file = os.path.join(input_dir,cache_file_name)\n","\n","if os.path.exists(cache_file):\n","    features_and_dataset = torch.load(cache_file)\n","    features, bert_dataset, examples = (\n","        features_and_dataset[\"features\"],features_and_dataset[\"dataset\"],features_and_dataset[\"examples\"])\n","else:\n","    # train_file_name=None, use the original dataset\n","    bert_dataset = load_dataset(bert_tokenizer, input_dir=input_dir, evaluate=False, cache_file_name=cache_file_name, train_file_name=None, append_method='append')\n","    features_and_dataset = torch.load(cache_file)\n","    features, bert_dataset, examples = (\n","        features_and_dataset[\"features\"],features_and_dataset[\"dataset\"],features_and_dataset[\"examples\"])\n","\n","t5_dataset_new = []\n","for feature in features:\n","    t5_dataset_new.append(t5_dataset[feature.example_index])\n","t5_dataset = t5_dataset_new\n","del t5_dataset_new\n","del examples\n","del features\n","del features_and_dataset\n","\n","# train\n","train_bert_with_t5(bert_model, t5_model, bert_tokenizer, bert_dataset, t5_dataset, device, pretrained_model, t5_pooled, epochs_trained=epochs_trained, \\\n","                   start_iter=start_iter, start_total_loss=start_total_loss, batch_size=2, save_criteria=save_criteria)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"He_78G3YTZqI"},"outputs":[],"source":["variant_name = 'Bert_with_T5_rewritten_epoch4_append_v3.2'\n","\n","#   create output directory for model parameters and to write predictions\n","if not os.path.exists(output_directory+'/'+variant_name) :\n","    os.makedirs(output_directory+'/'+variant_name)\n","            \n","model_to_save = bert_model.module if hasattr(bert_model, \"module\") else bert_model\n","model_to_save.save_pretrained(output_directory+'/'+variant_name)\n","bert_tokenizer.save_pretrained(output_directory+'/'+variant_name)"]},{"cell_type":"markdown","metadata":{"id":"XDyYsqyW9JEY"},"source":["## Prediction\n","\n","predict on dev dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1657209862265,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"f-lZDiEb4OcD","outputId":"b61654dd-1045-4c4e-978e-65d9646b7ca9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v3.2',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_embedding_epoch2_batch2',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_embedding_epoch4_batch2',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_all',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/model_weights0']"]},"metadata":{},"execution_count":7}],"source":["### Load two fine-tuned models, but with diffetent load methods\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","# method = '_replace_v2'\n","method = '_append_v3'\n","\n","# use catch file name\n","cache_file_name = 'bert-base-uncased_dev_with_T5{}'.format(method)\n","# use the predict file name\n","predict_file_name = 'coqa-dev-v1.0-{}_with_T5.json'.format(method[1:])\n","# # reset the catch file name\n","# cache_file_name = None\n","# # reset the predict file name\n","# predict_file_name = None\n","\n","model_parameter_directory"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1292197,"status":"ok","timestamp":1657211259914,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"quccxYdDyZNp","outputId":"2c1c87e8-1ddd-4e2f-a86d-47a63c573a52"},"outputs":[{"output_type":"stream","name":"stdout","text":["model_weights0\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Creating features from dataset file at /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data\n"]},{"output_type":"stream","name":"stderr","text":["Extracting features from dataset: 100%|██████████| 500/500 [05:48<00:00,  1.43it/s]\n","Extracting features from dataset: 100%|██████████| 7983/7983 [02:50<00:00, 46.93it/s]\n","Tag unique id to each example: 100%|██████████| 7983/7983 [00:00<00:00, 556188.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loading cache /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/bert-base-uncased_dev_epoch2\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 8565it [11:25, 12.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["save prediction file at: /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/model_weights0/predictions.json\n"]},{"output_type":"stream","name":"stderr","text":["Writing preditions: 100%|██████████| 7983/7983 [00:30<00:00, 262.55it/s]\n"]}],"source":["t5_pooled = True\n","\n","## load raw model\n","# t5 \n","t5_path = './mydata/MyDrive/CSNLP_Project/T5_model_COQAR/trained_models/t5_base_with_story_batch4_hist_20/epoch6.zip'\n","t5_model = torch.load(t5_path)\n","t5_input_tokenizer = t5base.get_input_tokenizer()   # or t5small \n","t5_output_tokenizer = t5base.get_output_tokenizer()\n","t5_model.to(device)\n","t5_model.train(False)\n","\n","# for m in model_parameter_directory:\n","m = model_parameter_directory[4]\n","variant_name = m.split('/')[-1]\n","print(variant_name)\n","# m = m + '/pytorch_model_2.bin'\n","bert_model = BertBaseUncasedModel_with_T5.from_pretrained(m) \n","# bert_model = BertBaseUncasedModel.from_pretrained(m) \n","bert_tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","bert_model.to(device)\n","\n","## get datasets\n","t5_dataset = make_t5_dataset(input_dir,file_type='dev',t5_type='base',train_file=train_file)\n","cache_file_name = 'bert-base-uncased_dev_epoch2'\n","predict_file_name = 'coqa-dev-v1.0.json'\n","\n","bert_dataset = load_dataset(bert_tokenizer, input_dir=input_dir, evaluate=True, cache_file_name=cache_file_name, predict_file_name=None, append_method='original')\n","\n","if cache_file_name is not None:\n","    cache_file = os.path.join(input_dir,cache_file_name)\n","\n","if os.path.exists(cache_file):\n","    features_and_dataset = torch.load(cache_file)\n","    features, dataset, examples = (\n","        features_and_dataset[\"features\"],features_and_dataset[\"dataset\"],features_and_dataset[\"examples\"])\n","\n","t5_dataset_new = []\n","for feature in features:\n","    t5_dataset_new.append(t5_dataset[feature.example_index])\n","t5_dataset = t5_dataset_new\n","del t5_dataset_new\n","\n","# Write_predictions(model, tokenizer, device, variant_name, input_dir=input_dir, output_directory=output_directory, cache_file_name=cache_file_name, predict_file_name=predict_file_name, method=method, append_method='append')\n","Write_predictions_with_T5(bert_model, t5_model, bert_tokenizer, device, variant_name, t5_dataset, t5_pooled, input_dir=input_dir,output_directory=output_directory,cache_file_name=cache_file_name,predict_file_name=predict_file_name,evaluation_batch_size=1,method='', append_method='original')"]},{"cell_type":"markdown","metadata":{"id":"L_AFYP9k0Yu1"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7728,"status":"ok","timestamp":1657211297946,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"4VY9u1rP0cSu","outputId":"73f3cbdb-6aca-47aa-8647-d4025fba14eb"},"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"children_stories\": {\n","    \"em\": 67.0,\n","    \"f1\": 76.2,\n","    \"turns\": 1425\n","  },\n","  \"literature\": {\n","    \"em\": 64.6,\n","    \"f1\": 74.2,\n","    \"turns\": 1630\n","  },\n","  \"mid-high_school\": {\n","    \"em\": 63.3,\n","    \"f1\": 73.8,\n","    \"turns\": 1653\n","  },\n","  \"news\": {\n","    \"em\": 67.8,\n","    \"f1\": 78.7,\n","    \"turns\": 1649\n","  },\n","  \"wikipedia\": {\n","    \"em\": 71.2,\n","    \"f1\": 80.2,\n","    \"turns\": 1626\n","  },\n","  \"reddit\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"science\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"in_domain\": {\n","    \"em\": 66.7,\n","    \"f1\": 76.6,\n","    \"turns\": 7983\n","  },\n","  \"out_domain\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"overall\": {\n","    \"em\": 66.7,\n","    \"f1\": 76.6,\n","    \"turns\": 7983\n","  }\n","}\n"]}],"source":["evaluator = CoQAEvaluator(input_dir+'/'+predict_file_name)\n","\n","# variant_name = 'Bert_with_T5_rewritten_epoch4_append_v2'\n","\n","# variant_name = 'Bert_from_original_Surya_epoch4'\n","\n","# variant_name = 'Bert_with_T5_rewritten_epoch4_replace'\n","\n","method = '_pooled'\n","\n","# m = model_parameter_directory[4]\n","# variant_name = m.split('/')[-1]\n","\n","pre_file_bert = output_directory+'/'+variant_name+'/'+'predictions{}.json'.format(method)\n","\n","# evaluate\n","with open(pre_file_bert) as f:\n","    pred_data = CoQAEvaluator.preds_to_dict(pre_file_bert)\n","\n","# write evaluate results\n","with open(output_directory+'/'+variant_name+'/'+'evaluation{}.json'.format(method), 'w') as f:\n","    json.dump(evaluator.model_performance(pred_data), f, indent=2)\n","\n","# show\n","print(json.dumps(evaluator.model_performance(pred_data), indent=2))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"BertWithT5.ipynb","provenance":[]},"gpuClass":"standard","interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"182eb850052e4d57ab0f03f6a1ff67de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_902ec0c1258c40319dc8781ac9617fdc","IPY_MODEL_116bde7fceb746d98ad7f47a2423a37c","IPY_MODEL_6a4390413e16481a82333c1644ffdd6e"],"layout":"IPY_MODEL_b8e3a4c15bd8449a987e319c36d38e79"}},"902ec0c1258c40319dc8781ac9617fdc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f47cddc3684492faef83d7bad08db99","placeholder":"​","style":"IPY_MODEL_92f113b09e3b46a6b6544ca728db19d1","value":"Downloading: 100%"}},"116bde7fceb746d98ad7f47a2423a37c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17c00fc5a8854a42a33c15054ecb3c4d","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6c5fedbddf143718033648a45ad9220","value":570}},"6a4390413e16481a82333c1644ffdd6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19819d5b5ca74d6788bdad74a2e5b844","placeholder":"​","style":"IPY_MODEL_41abebf76f1343dc97d7197361af8f6e","value":" 570/570 [00:00&lt;00:00, 20.9kB/s]"}},"b8e3a4c15bd8449a987e319c36d38e79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f47cddc3684492faef83d7bad08db99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92f113b09e3b46a6b6544ca728db19d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17c00fc5a8854a42a33c15054ecb3c4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6c5fedbddf143718033648a45ad9220":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"19819d5b5ca74d6788bdad74a2e5b844":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41abebf76f1343dc97d7197361af8f6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b60426ca9c74d0db109617acd6fafee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2dd593bf1294404395b64fa6d82b664b","IPY_MODEL_8be50df8307349729f05772880e5ef2e","IPY_MODEL_06569de5d65641579bf0d6457e5d97fb"],"layout":"IPY_MODEL_51a775c3793545cc9256f0206afffbda"}},"2dd593bf1294404395b64fa6d82b664b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3444b35d445243fcadd6dc9cc0ae5a7a","placeholder":"​","style":"IPY_MODEL_ab56edbea9054792bff0a5484507265b","value":"Downloading: 100%"}},"8be50df8307349729f05772880e5ef2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d091e0f0607a44989354707fe9c87173","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39090303e3fd4f208932ecace766399e","value":231508}},"06569de5d65641579bf0d6457e5d97fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88d5fbc30c974014a988df2a298c34bd","placeholder":"​","style":"IPY_MODEL_7d96da108fad408b8d9f8f78ce4b8323","value":" 226k/226k [00:00&lt;00:00, 595kB/s]"}},"51a775c3793545cc9256f0206afffbda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3444b35d445243fcadd6dc9cc0ae5a7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab56edbea9054792bff0a5484507265b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d091e0f0607a44989354707fe9c87173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39090303e3fd4f208932ecace766399e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88d5fbc30c974014a988df2a298c34bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d96da108fad408b8d9f8f78ce4b8323":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65e8c47bce5043aca9b3765ee6dff989":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_df5c88568c994d24bb7598b73390231f","IPY_MODEL_1f98c40b9de24b1695fe092192598f2a","IPY_MODEL_9b50714d54ca4fe1b194fda116b18e37"],"layout":"IPY_MODEL_33eadd1928084f74ace1bf8975ba0b46"}},"df5c88568c994d24bb7598b73390231f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3bb639455244b76a86b377c5338d1c3","placeholder":"​","style":"IPY_MODEL_2271bbabc2794fee893eec76e9d83818","value":"Downloading: 100%"}},"1f98c40b9de24b1695fe092192598f2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12c4470f00ca48c4832ec507a27f6b26","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c76f4d5cc7914439a5c0d288bd73ab8b","value":28}},"9b50714d54ca4fe1b194fda116b18e37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5d8a18596454be8bfd65d5f81345927","placeholder":"​","style":"IPY_MODEL_2c9c7cf4016e45e2959a721b369ac4d5","value":" 28.0/28.0 [00:00&lt;00:00, 766B/s]"}},"33eadd1928084f74ace1bf8975ba0b46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3bb639455244b76a86b377c5338d1c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2271bbabc2794fee893eec76e9d83818":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12c4470f00ca48c4832ec507a27f6b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76f4d5cc7914439a5c0d288bd73ab8b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5d8a18596454be8bfd65d5f81345927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9c7cf4016e45e2959a721b369ac4d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42dad6122bb74ed0991b075672ecf688":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_437b631280f4469e9b8ef3ff3961c161","IPY_MODEL_4de21ca23aad424ca414be9c27d61ef6","IPY_MODEL_95dfea02ebdf4228aed7c702d30f9a68"],"layout":"IPY_MODEL_b1269fe4657a4ed4a5cccd0bc916d30c"}},"437b631280f4469e9b8ef3ff3961c161":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbd8361f446a407e95ea448dbd4bf554","placeholder":"​","style":"IPY_MODEL_7c237bcfe60d42fc9b2d3fdf93878d6a","value":"Downloading: 100%"}},"4de21ca23aad424ca414be9c27d61ef6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f59736e7f13a40a0a08b6196921ac2ff","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f058fe7d6544248b681b33a49de5626","value":440473133}},"95dfea02ebdf4228aed7c702d30f9a68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9656305b51294a1a9415559b6c8bda45","placeholder":"​","style":"IPY_MODEL_7e4861065db04e488f32d7995392061d","value":" 420M/420M [00:06&lt;00:00, 67.1MB/s]"}},"b1269fe4657a4ed4a5cccd0bc916d30c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbd8361f446a407e95ea448dbd4bf554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c237bcfe60d42fc9b2d3fdf93878d6a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f59736e7f13a40a0a08b6196921ac2ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f058fe7d6544248b681b33a49de5626":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9656305b51294a1a9415559b6c8bda45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e4861065db04e488f32d7995392061d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}