{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138967,"status":"ok","timestamp":1656707604046,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"JfgX6lC-CeEN","outputId":"ecb96c71-77b5-4a6f-8159-652f0dbbfd99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 52.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 55.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 12.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n","Mounted at ./mydata\n"]}],"source":["!pip install transformers\n","#==4.19.2\n","from google.colab import drive\n","drive.mount('./mydata')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":229,"status":"ok","timestamp":1656707621901,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"wyzGkzsuHNAA"},"outputs":[],"source":["import sys\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/Bert_model_COQA')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":10251,"status":"ok","timestamp":1656707632894,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"UZAJcRiiEZqp"},"outputs":[],"source":["import collections\n","import glob\n","import os\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tqdm, trange\n","from transformers import (AdamW, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, BertTokenizer, BertModel, BertConfig)\n","from processors.coqa import Extract_Features, Processor, Result\n","from processors.evaluate import CoQAEvaluator, parse_args\n","from processors.Bert_model import BertBaseUncasedModel, load_dataset, Write_predictions\n","\n","import torch\n","import csv\n","import numpy as np\n","\n","import json\n","\n","# locations\n","train_file=\"coqa-train-v1.0.json\"\n","predict_file=\"coqa-dev-v1.0.json\"\n","cur_path = os.getcwd()\n","output_directory = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models\"\n","input_dir = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data\"\n","# can use either BERT base or BERT large\n","pretrained_model=\"bert-base-uncased\"\n","# pretrained_model=\"bert-large-uncased\"\n","epochs = 2\n","evaluation_batch_size=16\n","train_batch_size=2"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1656707632895,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"jx46LBgUCeEn"},"outputs":[],"source":["### train function\n","\n","def train(train_dataset, model, tokenizer, device, batch_size=train_batch_size):\n","\n","    train_sampler = RandomSampler(train_dataset) \n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","    t_total = len(train_dataloader) // 1 * epochs\n","\n","    # Preparing optimizer and scheduler\n","    optimizer_parameters = [{\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])],\"weight_decay\": 0.01,},{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])], \"weight_decay\": 0.0}]\n","    optimizer = AdamW(optimizer_parameters,lr=1e-5, eps=1e-8)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2000, num_training_steps=t_total)\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if os.path.isfile(os.path.join(pretrained_model, \"optimizer.pt\")) and os.path.isfile(os.path.join(pretrained_model, \"scheduler.pt\")):\n","        optimizer.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"scheduler.pt\")))\n","\n","    counter = 1\n","    epochs_trained = 0\n","    train_loss, loss = 0.0, 0.0\n","    model.zero_grad()\n","    iterator = trange(epochs_trained, int(epochs), desc=\"Epoch\", disable=False)\n","    for _ in iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n","        for i,batch in enumerate(epoch_iterator):\n","            model.train()\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs = { \"input_ids\": batch[0],\"token_type_ids\": batch[1], \"attention_mask\": batch[2],\"start_positions\": batch[3],\"end_positions\": batch[4],\"rational_mask\": batch[5],\"cls_idx\": batch[6]}\n","            # loss = model(**inputs, return_dict=False)\n","            loss = model(**inputs)\n","            loss.backward()\n","            train_loss += loss.item()\n","\n","            #   optimizing training parameters\n","            if (i + 1) % 1 == 0:\n","                optimizer.step()\n","                scheduler.step()  \n","                model.zero_grad()\n","                counter += 1\n","                #   Saving model weights every 1000 iterations\n","                if counter % 1000 == 0:\n","                    output_dir = os.path.join(output_directory, \"model_weights\"+str(epochs_trained))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    model_to_save = model.module if hasattr(model, \"module\") else model\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            if (i+1) % 1000 == 0:\n","                print('iter: {}, loss: {}'.format(i,train_loss/counter))\n","    return train_loss/counter"]},{"cell_type":"markdown","metadata":{"id":"n-avtGOw9JEV"},"source":["## Training"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["6953c87238bf4c77ac090fb0470a2ac2","5bbb8da255094fc8a1c5e0cee7c6c263","75538c94e6e449e9a09cc71a524a178c","ce5f2c1a19bf4c7ea358a8d6457ce9d9","27d61ee0ffbd4795824b80993e3fbe36","785c1519c83a4dffbea0286ec14e516a","48aef52c0a6641acaabecd0c15f1fa22","6c326e4aaa9946779aee5a373bb21b16","0d9137ff61014f46a00ab7caff51d9a3","3ad5f8bb95254ef281584ec5f97af3de","99f89a8ad0b54d48bcd99f25c3b11fbe","857c63fd68a34525b7681d382c007842","06c6e6b1065444f9a1af7ace5ac3681d","78ed83fa46de4853b1bfe3c84088945b","78b94f3790624c14aea3ae90c2ec1301","d6bda98bc5b74ca9a5ab476f0b7e2bdc","4f030b0c3e014b6d90367bce963b15b7","709f0b5ccaf1435a8ec8a4250e3948de","0d50d5cd5ac146a6bf38aa6fa927d149","9d3ea2da19ae4ffdbd6a93de9022b90b","0c3079a0024e420ba5068ce3dcbbcf5f","026e09fb9cdc4784ae30390f5bb42779","e7a9bff02622434e9aa06dfc0e67afce","d57bcaf3d3b247bb915ddb6b7b433171","ee332a8986d3483087e34c667ad602a0","2a787c6219e04c389b8795b2585b51e6","c1d4c964a2154aa894a6c5a1754c9469","c234bb1da0114bc58dbb5d767cd1eb37","b33198cbdf8347b69a13f5b86400db1c","4f8600a4abb94b0f9bbe3b3a5c90991a","e02df13a59e445c2a70010907998f3c3","8435166a861e4693b909756f6cbce8a9","4db16c8ff8ba42efb0e3b01fa4e9c223","742070a123194b879d177e5187e33156","047eba00a46e4cf589fa0f432da9cead","66bcce2d27ee45a2a4b0e15dc73aa5d4","e81298b05159499cb654f800e9e8eb03","cc27b7c8c5f34d139127c997ab3792fb","4b9663d2e7dc47d2a38a6dce8f932b62","fcda55f2d4c94318ad8a8d1c517a384e","8366aa9ad5a44325b8ee49c65e74ab50","49cba518669f4fa082bd7e941f83c772","f699b137f59d4849aaa226e31455677c","5f4ead0496ac403d95fa16586dbebd17"]},"executionInfo":{"elapsed":150796,"status":"ok","timestamp":1656707796801,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"o4RsfgerCeEp","outputId":"d3e746e4-d438-4fb0-824b-89dd75d5685e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6953c87238bf4c77ac090fb0470a2ac2","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"857c63fd68a34525b7681d382c007842","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7a9bff02622434e9aa06dfc0e67afce","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"742070a123194b879d177e5187e33156","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertBaseUncasedModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertBaseUncasedModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertBaseUncasedModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertBaseUncasedModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['fc.weight', 'fc.bias', 'linear1.weight', 'linear2.weight', 'linear1.bias', 'linear2.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Loading cache /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/bert-base-uncased_train_with_T5_replace_all\n"]}],"source":["#   check if gpu is available to use it or not\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#   initialize configurations and tokenizer of Bert model \n","config = BertConfig.from_pretrained(pretrained_model, return_dict=False)\n","tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n","\n","model = BertBaseUncasedModel.from_pretrained(pretrained_model, from_tf=bool(\".ckpt\" in pretrained_model), config=config,cache_dir=None,)\n","# print(model)\n","model.to(device)\n","\n","# if (os.path.exists(output_directory) and os.listdir(output_directory)):\n","#     raise ValueError(\"Output directory \" + output_directory + \" already exists, Change output_directory name\")\n","\n","method = 'replace_all'\n","\n","#   Loading dataset and training\n","# this command will take several hours\n","cache_file_name = 'bert-base-uncased_train_with_T5_{}'.format(method)\n","\n","train_file_name = 'coqa-train-v1.0-{}_with_T5.json'.format('append_v3')\n","\n","train_dataset = load_dataset(tokenizer, input_dir=input_dir, evaluate=False, cache_file_name=cache_file_name, train_file_name=train_file_name, append_method='replace_all')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvKBU3GgCeEr","outputId":"73d191dc-52ac-4f3b-de58-5d8f439fc4f9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["iter: 999, loss: 5.533492145242986\n","iter: 1999, loss: 4.690178165848049\n"]}],"source":["# train the model on CoQA\n","train_loss = train(train_dataset, model, tokenizer, device)\n","\n","variant_name = 'Bert_with_T5_rewritten_epoch2_replace_all'\n","\n","#   create output directory for model parameters and to write predictions\n","if not os.path.exists(output_directory+'/'+variant_name) :\n","    os.makedirs(output_directory+'/'+variant_name)\n","            \n","model_to_save = model.module if hasattr(model, \"module\") else model\n","model_to_save.save_pretrained(output_directory+'/'+variant_name)\n","tokenizer.save_pretrained(output_directory+'/'+variant_name)"]},{"cell_type":"markdown","metadata":{"id":"XDyYsqyW9JEY"},"source":["## Prediction\n","\n","predict on dev dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_1nMH-SIivu"},"outputs":[],"source":["#   check if gpu is available to use it or not\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#   Loading Bert model for writing predictions\n","# model = BertBaseUncasedModel.from_pretrained(output_directory)\n","# tokenizer = BertTokenizer.from_pretrained(output_directory, do_lower_case=True)\n","# model.to(device)\n","# run for different parameters\n","\n","# check if gpu is available to use it or not\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","# for m in model_parameter_directory:\n","#     variant_name = m.split('/')[-1]\n","#     model = BertBaseUncasedModel.from_pretrained(m) \n","#     tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","#     model.to(device)\n","#     Write_predictions(model, tokenizer, device, variant_name)\n","# train_dataset = load_dataset(tokenizer, evaluate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1656231737861,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"g6PF9-kg9pvR","outputId":"7952ac83-3a9f-450a-a6a1-44ee668f23b8"},"outputs":[{"data":{"text/plain":["['/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_from_original_Surya_epoch4',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v2']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","cache_file_name = 'bert-base-uncased_dev_with_T5_append'\n","\n","predict_file_name = 'coqa-dev-v1.0.json'\n","\n","model_parameter_directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":236667,"status":"ok","timestamp":1655734894838,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"uOOl8SQ2s02q","outputId":"7b918754-f4e4-4293-e2da-26100a9b1ca1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading cache /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/bert-base-uncased_dev_with_T5_append\n"]},{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 8775/8775 [03:14<00:00, 45.15it/s]\n","Writing preditions: 100%|██████████| 7983/7983 [00:28<00:00, 284.79it/s]\n"]}],"source":["# for m in model_parameter_directory:\n","m = model_parameter_directory[1]\n","variant_name = m.split('/')[-1]\n","# m = m + '/pytorch_model_2.bin'\n","model = BertBaseUncasedModel.from_pretrained(m) \n","tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","model.to(device)\n","Write_predictions(model, tokenizer, device, variant_name, input_dir=input_dir, output_directory=output_directory, cache_file_name=cache_file_name, predict_file_name=None,method='append_v3.2', append_method='append')"]},{"cell_type":"markdown","metadata":{"id":"L_AFYP9k0Yu1"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VY9u1rP0cSu"},"outputs":[],"source":["evaluator = CoQAEvaluator(input_dir+'/'+predict_file)\n","\n","variant_name = 'Bert_from_original_Surya_epoch4'\n","\n","pre_file_bert = output_directory+'/'+variant_name+'/'+'predictions.json'\n","\n","# evaluate\n","with open(pre_file_bert) as f:\n","    pred_data = CoQAEvaluator.preds_to_dict(pre_file_bert)\n","\n","# write evaluate result\n","with open(output_directory+'/'+variant_name+'/'+'evaluation.json', 'w') as f:\n","    json.dump(evaluator.model_performance(pred_data), f, indent=2)\n","\n","# show\n","# print(json.dumps(evaluator.model_performance(pred_data), indent=2))"]},{"cell_type":"markdown","metadata":{"id":"QZt4mghfQyTj"},"source":["get_domain_scores --> model_performance --> get_raw_scores --> compute_turn_score --> _compute_turn_score --> compute_exact /  compute_f1\n"]},{"cell_type":"markdown","metadata":{"id":"N_xpwsOQpiva"},"source":["## Test any input on the fine-tuned model: By ZYZ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EAPoJPZAequ"},"outputs":[],"source":["### this cell load the fine tuned model\n","\n","# check if gpu is available to use it or not\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","for m in model_parameter_directory:\n","    variant_name = m.split('/')[-1]\n","    model = BertBaseUncasedModel.from_pretrained(m) \n","    tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","    model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7961,"status":"ok","timestamp":1652290735026,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"Zy243hvSJv_J","outputId":"72eeff4e-6a9b-49a5-995e-a29851da5c20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading cache /content/mydata/MyDrive/Colab Notebooks/data/bert-base-uncased_dev_test\n"]}],"source":["### load the dev dataset with gold answer\n","\n","cache_file = os.path.join(input_dir,\"bert-base-uncased_dev_test\")\n","\n","if os.path.exists(cache_file):\n","    print(\"Loading cache\",cache_file)\n","    features_and_dataset = torch.load(cache_file)\n","    features, dataset, examples = (\n","        features_and_dataset[\"features\"],features_and_dataset[\"dataset\"],features_and_dataset[\"examples\"])\n","else:\n","    print(\"Creating features from dataset file at\", input_dir)\n","\n","    processor = Processor()\n","\n","    examples = processor.get_examples(input_dir, 2, filename=predict_file, threads=1)\n","\n","    # max_seq_length is the total length for input sequence of BERT \n","    features, dataset = Extract_Features(examples=examples,tokenizer=tokenizer,max_seq_length=512, doc_stride=128, max_query_length=64, is_training=True, threads=1)\n","    #   caching it in a cache file to reduce time\n","    torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cache_file)\n","\n","# create evaluation_test_dataloader\n","evalutation_test_sampler = SequentialSampler(dataset)\n","evaluation_test_dataloader = DataLoader(dataset, sampler=evalutation_test_sampler, batch_size=1)\n"]},{"cell_type":"markdown","metadata":{"id":"d_yk1-jrRIug"},"source":["1. model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n","2. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fa8h6OX1F0r"},"outputs":[],"source":["def predict(batch):\n","  '''\n","  given input_ids of text, QA history and current question, predict answer with \n","  model and compare with ground truth answer span\n","  '''\n","  model.eval()\n","  batch = tuple(t.to(device) for t in batch)\n","  with torch.no_grad():\n","      inputs = {\"input_ids\": batch[0],\"token_type_ids\": batch[1],\"attention_mask\": batch[2]}\n","      inputs_text = inputs[\"input_ids\"]\n","      outputs = model(**inputs)\n","\n","  # convert ids to texts\n","  input_ids = inputs_text[0]\n","  # tokens are all QA and text\n","  tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","  # sep_idx = list(input_ids).index(tokenizer.sep_token_id)\n","  # question = \" \".join(tokens[:(sep_idx+1)])\n","  # sep_idx2 = list(input_ids[(sep_idx+1):]).index(tokenizer.sep_token_id)\n","  # text = \" \".join(tokens[(sep_idx+1):(sep_idx2+(sep_idx+1))])\n","\n","  def convert_to_list(tensor):\n","      return tensor.detach().cpu().tolist()\n","      \n","  # extract answer from prediction of bert\n","  output = [convert_to_list(output[0]) for output in outputs]\n","  start_logits, end_logits, yes_logits, no_logits, unk_logits = output\n","  start_pos = np.argmax(start_logits)\n","  end_pos = np.argmax(end_logits)\n","\n","  print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n","  answer = \" \".join(tokens[start_pos:end_pos+1])\n","  print(\"Answer:\\n{}.\".format(answer.capitalize()))\n","\n","  # pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":226,"status":"ok","timestamp":1652291599956,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"hgpVaVcbk5oq","outputId":"50c69034-edd3-44b8-cba6-a38082ac1f73"},"outputs":[{"name":"stdout","output_type":"stream","text":["question: [CLS] where did she live ? in a barn [SEP] did she live alone ? no [SEP] who did she live with ? [SEP] \n","\n"," text: upon a time , in a barn near a farm house , there lived a little white kitten named cotton . cotton lived high up in a nice warm place above the barn where all of the farmer ' s horses slept . but cotton was n ' t alone in her little home above the barn , oh no . she shared her hay bed with her mommy and 5 other sisters . all of her sisters were cute and fluffy , like cotton . but she was the only white one in the bunch . the rest of her sisters were all orange with beautiful white tiger stripes like cotton ' s mommy . being different made cotton quite sad . she often wished she looked like the rest of her family . so one day , when cotton found a can of the old farmer ' s orange paint , she used it to paint herself like them . when her mommy and sisters found her they started laughing . \" what are you doing , cotton ? ! \" \" i only wanted to be more like you \" . cotton ' s mommy rubbed her face on cotton ' s and said \" oh cotton , but your fur is so pretty and special , like you . we would never want you to be any other way \" . and with that , cotton ' s mommy picked her up and dropped her into a big bucket of water . when cotton came out she was herself again . her sisters licked her face until cotton ' s fur was all all dry . \" do n ' t ever do that again , cotton ! \" they all cried . \" next time you might mess up that pretty white fur of yours and we would n ' t want that ! \" then cotton thought , \" i change my mind . i like being special \" . \n","\n"," gold answer: with her mommy and 5 other sisters\n"]}],"source":["random_num = np.random.randint(0,len(evaluation_test_dataloader))\n","random_num = 3\n","\n","## evaluation_test_dataloader is not iteratable\n","## dummy method\n","count = 0\n","for batch in evaluation_test_dataloader:\n","    # print(len(batch[3]))\n","    if count >= random_num:\n","        break\n","    count += 1\n","\n","# data from batch\n","input_ids = batch[0][0]\n","token_type_ids = batch[1][0]\n","tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","# sep_idx = list(input_ids).index(tokenizer.sep_token_id)\n","sep_idx = torch.where(token_type_ids==1)[0][0]\n","question = \" \".join(tokens[:(sep_idx)])\n","sep_idx2 = list(input_ids[(sep_idx+1):]).index(tokenizer.sep_token_id)\n","text = \" \".join(tokens[(sep_idx+1):(sep_idx2+(sep_idx+1))])\n","\n","# extract gold answer\n","start_positions = batch[3][0]\n","end_positions = batch[4][0]\n","gold_answer = \" \".join(tokens[start_positions:end_positions+1])\n","\n","print('question: '+question,'\\n\\n','text: '+text,'\\n\\n','gold answer: '+gold_answer)#+data[\"answer\"][random_num])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1652291603571,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"z-1792vrN2hg","outputId":"946f244d-b798-4b70-cd90-6246ce9164b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Question:\n","[cls] where did she live ? in a barn [sep] did she live alone ? no [sep] who did she live with ? [sep]\n","Answer:\n","Her mommy and 5 other sisters.\n"]}],"source":["predict(batch)"]},{"cell_type":"markdown","metadata":{"id":"2JKyB4a6i0oh"},"source":["## Write all the failure cases"]},{"cell_type":"markdown","metadata":{"id":"EQpQpvMfRvOW"},"source":["#### Use evaluator.compute_turn_score to evaluate each case\n","\n","e.g.\n","\n","evaluator.compute_turn_score('3dr23u6we5exclen4th8uq9rb42tel', 4, 'her mommy and 5 other sisters')\n","\n","output: {'em': 1.0, 'f1': 1.0} (exact match and f1 score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gAzZ2Tdiu_Y"},"outputs":[],"source":["# failure criteria\n","criteria_flag = 'full'\n","\n","# tuples for all prediction data\n","pre_data_list = []\n","for key in pred_data.keys():\n","    pre_data_list.append(key + (pred_data[key],) )\n","\n","# find out all the failure cases: their ids\n","fail_results = []\n","for prediction in pre_data_list:\n","    result = evaluator.compute_turn_score(prediction[0],prediction[1],prediction[2])\n","    # totally wrong\n","    if criteria_flag == 'full':\n","        if result == {'em': 0.0, 'f1': 0.0}:\n","            fail_results.append(prediction)\n","    # not fully correct\n","    elif criteria_flag == 'partial':\n","        if result != {'em': 1.0, 'f1': 1.0}:\n","            fail_results.append(prediction)\n","    # print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652301186201,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"JJ5Jc5XUz9PU","outputId":"10ad3d83-4b0e-41cb-fdde-eacf2ac23b6d"},"outputs":[{"data":{"text/plain":["0.1663535011900288"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["len(fail_results) / len(pre_data_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrOrErxuixSk"},"outputs":[],"source":["# write results\n","with open(output_directory+'/'+variant_name+'/'+'fully_failed_predictions.csv', mode='w+', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(['passage_id','turn_id','story_type', 'story', 'history QA', 'current question', 'gold_answers', 'failed_prediction', 'scores'])\n","\n","with open(output_directory+'/'+variant_name+'/'+'fully_failed_predictions.csv', mode='a+', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.writer(f)\n","    \n","    for fail_result in fail_results:\n","        story_id = fail_result[0]\n","        turn_id = fail_result[1]\n","        key = (story_id, turn_id)\n","        a_gold_list = evaluator.gold_data[key]\n","        scores = evaluator.compute_turn_score(fail_result[0],fail_result[1],fail_result[2])\n","        # evaluator.questions[turn_id]\n","        writer.writerow([story_id,turn_id,evaluator.id_to_source[story_id],evaluator.story_dict[story_id],\\\n","                         evaluator.question_dict[story_id][:turn_id-1],evaluator.question_dict[story_id][turn_id-1],a_gold_list, fail_result[2], scores])\n"]},{"cell_type":"markdown","metadata":{"id":"utcqU6v9xJva"},"source":["### Test results of yes/no answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzxs27q3xN0R"},"outputs":[],"source":["# tuples for all prediction data\n","yn_data_list = []\n","for key in pred_data.keys():\n","    if pred_data[key] in ['yes','no']:\n","        yn_data_list.append(key + (pred_data[key],) )\n","\n","\n","# find out all the failure cases: their ids\n","yn_fail_results = []\n","for prediction in yn_data_list:\n","    result = evaluator.compute_turn_score(prediction[0],prediction[1],prediction[2])\n","    # not fully correct\n","    # if result != {'em': 1.0, 'f1': 1.0}:\n","    # totally wrong\n","    if result == {'em': 0.0, 'f1': 0.0}:\n","        yn_fail_results.append(prediction)\n","    # print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1652301233734,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"dtBu46GBzQlL","outputId":"3d32d9a5-a928-45cb-f8c7-a12c6abcde45"},"outputs":[{"data":{"text/plain":["0.22059376174370537"]},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":["yn_ratio = len(yn_data_list) / len(pred_data)\n","yn_ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1652301372268,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"K10NZwq81Wgr","outputId":"d68c3d5d-27e3-47bd-9cb9-0e0f724b6e45"},"outputs":[{"data":{"text/plain":["0.1486660237865638"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["non_yn_failure_ratio = (len(fail_results)-len(yn_fail_results)) / (len(pre_data_list)-len(yn_data_list))\n","non_yn_failure_ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1652301254288,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"LDQOn2EPzSDr","outputId":"917616ea-d4c6-4db8-eda5-b02196f9ae1a"},"outputs":[{"data":{"text/plain":["0.22884724588302102"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["yn_failure_ratio = len(yn_fail_results) / len(yn_data_list)\n","yn_failure_ratio"]},{"cell_type":"markdown","metadata":{"id":"kZTdQd0x1G9x"},"source":["Observation: The fully wrong ({'em': 0.0, 'f1': 0.0}) ratio of yes/no type question is higher then the normal question.\n","\n","\n","Need to construct a dictionary for computing the overall F1 score of these two different type of questions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWGdX5rdz4CB"},"outputs":[],"source":["# tuples for all prediction data\n","yn_dict = {}\n","non_yn_dict = {}\n","yn_turns  = {}\n","for i in list(domain_mappings.values()):\n","    yn_turns[i] = 0\n","    \n","for key in pred_data.keys():\n","    if pred_data[key] in ['yes','no']:\n","        story_type = evaluator.id_to_source[key[0]]\n","        yn_turns[domain_mappings[story_type]] += 1\n","        yn_dict[key] = pred_data[key]\n","    else:\n","        non_yn_dict[key] = pred_data[key]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652302902453,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"sms4ulTb67UH","outputId":"a7c53c24-0a2e-4159-9d4c-9c61399ea614"},"outputs":[{"data":{"text/plain":["['children_stories',\n"," 'literature',\n"," 'mid-high_school',\n"," 'news',\n"," 'wikipedia',\n"," 'science',\n"," 'reddit']"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["list(domain_mappings.values())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652302594220,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"dKm0KKbU6LmW","outputId":"51ccad7f-b8fd-4441-bc37-1d9e1aa0235f"},"outputs":[{"data":{"text/plain":["290"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["yn_turns[story_type]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":970,"status":"ok","timestamp":1652303069989,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"e9hYB58U2TSO","outputId":"7b878721-8e5b-4db1-bb14-e332e1761ada"},"outputs":[{"name":"stdout","output_type":"stream","text":["no yes/no answer in reddit\n","no yes/no answer in science\n"]}],"source":["# evaluator.model_performance(yn_dict)\n","result_yn = json.dumps(evaluator.model_performance(yn_dict), indent=2)\n","result_yn = json.loads(result_yn)\n","for case in result_yn:\n","    if case not in ['in_domain', 'out_domain','overall']:\n","        if yn_turns[case] == 0:\n","            print('no yes/no answer in {}'.format(case))\n","            pass\n","        else:\n","            result_yn[case]['em'] = result_yn[case]['em'] * result_yn[case]['turns'] / yn_turns[case]\n","            result_yn[case]['f1'] = result_yn[case]['f1'] * result_yn[case]['turns'] / yn_turns[case]\n","            result_yn[case]['turns'] = yn_turns[case]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1652303081553,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"6qSJkOVz8BB3","outputId":"85d37883-39da-49f1-b77b-7288e4501cd2"},"outputs":[{"data":{"text/plain":["{'children_stories': {'em': 74.27762039660055,\n","  'f1': 74.27762039660055,\n","  'turns': 353},\n"," 'in_domain': {'em': 16.8, 'f1': 16.8, 'turns': 7983},\n"," 'literature': {'em': 74.05432098765431,\n","  'f1': 74.05432098765431,\n","  'turns': 405},\n"," 'mid-high_school': {'em': 75.67442455242966,\n","  'f1': 75.67442455242966,\n","  'turns': 391},\n"," 'news': {'em': 78.35310559006211, 'f1': 78.35310559006211, 'turns': 322},\n"," 'out_domain': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'overall': {'em': 16.8, 'f1': 16.8, 'turns': 7983},\n"," 'reddit': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'science': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'wikipedia': {'em': 80.17862068965518, 'f1': 80.17862068965518, 'turns': 290}}"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["result_yn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3924,"status":"ok","timestamp":1652303205897,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"NicPvA_s7l6p","outputId":"4ad2cee6-5e96-4007-d613-80ea5357da35"},"outputs":[{"name":"stdout","output_type":"stream","text":["no yes/no answer in reddit\n","no yes/no answer in science\n"]}],"source":["# evaluator.model_performance(yn_dict)\n","result_non_yn = json.dumps(evaluator.model_performance(non_yn_dict), indent=2)\n","result_non_yn = json.loads(result_non_yn)\n","for case in result_non_yn:\n","    if case not in ['in_domain', 'out_domain','overall']:\n","        if yn_turns[case] == result_non_yn[case]['turns']:\n","            print('no yes/no answer in {}'.format(case))\n","            pass\n","        else:\n","            result_non_yn[case]['em'] = result_non_yn[case]['em'] * result_non_yn[case]['turns'] / (result_non_yn[case]['turns']-yn_turns[case])\n","            result_non_yn[case]['f1'] = result_non_yn[case]['f1'] * result_non_yn[case]['turns'] / (result_non_yn[case]['turns']-yn_turns[case])\n","            result_non_yn[case]['turns'] = (result_non_yn[case]['turns']-yn_turns[case])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1652303212473,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"SUMq025_4CMy","outputId":"1022d8ac-0744-43d9-dac5-25f93289f5d2"},"outputs":[{"data":{"text/plain":["{'children_stories': {'em': 60.748600746268664,\n","  'f1': 73.64272388059702,\n","  'turns': 1072},\n"," 'in_domain': {'em': 48.1, 'f1': 58.1, 'turns': 7983},\n"," 'literature': {'em': 58.81306122448979,\n","  'f1': 71.98612244897959,\n","  'turns': 1225},\n"," 'mid-high_school': {'em': 57.63232963549921,\n","  'f1': 71.25451664025357,\n","  'turns': 1262},\n"," 'news': {'em': 63.62381311228335, 'f1': 76.92019593067067, 'turns': 1327},\n"," 'out_domain': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'overall': {'em': 48.1, 'f1': 58.1, 'turns': 7983},\n"," 'reddit': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'science': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'wikipedia': {'em': 67.4254491017964, 'f1': 78.37904191616767, 'turns': 1336}}"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["result_non_yn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4786,"status":"ok","timestamp":1652303268221,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"RQEzPaf04E59","outputId":"ca75b98c-5360-4f85-bd74-591582be8141"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"children_stories\": {\n","    \"em\": 64.1,\n","    \"f1\": 73.8,\n","    \"turns\": 1425\n","  },\n","  \"literature\": {\n","    \"em\": 62.5,\n","    \"f1\": 72.5,\n","    \"turns\": 1630\n","  },\n","  \"mid-high_school\": {\n","    \"em\": 61.9,\n","    \"f1\": 72.3,\n","    \"turns\": 1653\n","  },\n","  \"news\": {\n","    \"em\": 66.6,\n","    \"f1\": 77.2,\n","    \"turns\": 1649\n","  },\n","  \"wikipedia\": {\n","    \"em\": 69.6,\n","    \"f1\": 78.7,\n","    \"turns\": 1626\n","  },\n","  \"reddit\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"science\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"in_domain\": {\n","    \"em\": 65.0,\n","    \"f1\": 74.9,\n","    \"turns\": 7983\n","  },\n","  \"out_domain\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"overall\": {\n","    \"em\": 65.0,\n","    \"f1\": 74.9,\n","    \"turns\": 7983\n","  }\n","}\n"]}],"source":["print(json.dumps(evaluator.model_performance(pred_data), indent=2))"]},{"cell_type":"markdown","metadata":{"id":"4B63hRUr81dG"},"source":["so the actuall overall f1 score for yes/no question is higher"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Bert_convqa_with_evaluate.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"026e09fb9cdc4784ae30390f5bb42779":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"047eba00a46e4cf589fa0f432da9cead":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b9663d2e7dc47d2a38a6dce8f932b62","placeholder":"​","style":"IPY_MODEL_fcda55f2d4c94318ad8a8d1c517a384e","value":"Downloading: 100%"}},"06c6e6b1065444f9a1af7ace5ac3681d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f030b0c3e014b6d90367bce963b15b7","placeholder":"​","style":"IPY_MODEL_709f0b5ccaf1435a8ec8a4250e3948de","value":"Downloading: 100%"}},"0c3079a0024e420ba5068ce3dcbbcf5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d50d5cd5ac146a6bf38aa6fa927d149":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d9137ff61014f46a00ab7caff51d9a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27d61ee0ffbd4795824b80993e3fbe36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a787c6219e04c389b8795b2585b51e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8435166a861e4693b909756f6cbce8a9","placeholder":"​","style":"IPY_MODEL_4db16c8ff8ba42efb0e3b01fa4e9c223","value":" 28.0/28.0 [00:00&lt;00:00, 883B/s]"}},"3ad5f8bb95254ef281584ec5f97af3de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48aef52c0a6641acaabecd0c15f1fa22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"49cba518669f4fa082bd7e941f83c772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b9663d2e7dc47d2a38a6dce8f932b62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db16c8ff8ba42efb0e3b01fa4e9c223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f030b0c3e014b6d90367bce963b15b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f8600a4abb94b0f9bbe3b3a5c90991a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bbb8da255094fc8a1c5e0cee7c6c263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_785c1519c83a4dffbea0286ec14e516a","placeholder":"​","style":"IPY_MODEL_48aef52c0a6641acaabecd0c15f1fa22","value":"Downloading: 100%"}},"5f4ead0496ac403d95fa16586dbebd17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66bcce2d27ee45a2a4b0e15dc73aa5d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8366aa9ad5a44325b8ee49c65e74ab50","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49cba518669f4fa082bd7e941f83c772","value":440473133}},"6953c87238bf4c77ac090fb0470a2ac2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bbb8da255094fc8a1c5e0cee7c6c263","IPY_MODEL_75538c94e6e449e9a09cc71a524a178c","IPY_MODEL_ce5f2c1a19bf4c7ea358a8d6457ce9d9"],"layout":"IPY_MODEL_27d61ee0ffbd4795824b80993e3fbe36"}},"6c326e4aaa9946779aee5a373bb21b16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"709f0b5ccaf1435a8ec8a4250e3948de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"742070a123194b879d177e5187e33156":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_047eba00a46e4cf589fa0f432da9cead","IPY_MODEL_66bcce2d27ee45a2a4b0e15dc73aa5d4","IPY_MODEL_e81298b05159499cb654f800e9e8eb03"],"layout":"IPY_MODEL_cc27b7c8c5f34d139127c997ab3792fb"}},"75538c94e6e449e9a09cc71a524a178c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c326e4aaa9946779aee5a373bb21b16","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d9137ff61014f46a00ab7caff51d9a3","value":570}},"785c1519c83a4dffbea0286ec14e516a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78b94f3790624c14aea3ae90c2ec1301":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c3079a0024e420ba5068ce3dcbbcf5f","placeholder":"​","style":"IPY_MODEL_026e09fb9cdc4784ae30390f5bb42779","value":" 226k/226k [00:00&lt;00:00, 873kB/s]"}},"78ed83fa46de4853b1bfe3c84088945b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d50d5cd5ac146a6bf38aa6fa927d149","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d3ea2da19ae4ffdbd6a93de9022b90b","value":231508}},"8366aa9ad5a44325b8ee49c65e74ab50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8435166a861e4693b909756f6cbce8a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"857c63fd68a34525b7681d382c007842":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06c6e6b1065444f9a1af7ace5ac3681d","IPY_MODEL_78ed83fa46de4853b1bfe3c84088945b","IPY_MODEL_78b94f3790624c14aea3ae90c2ec1301"],"layout":"IPY_MODEL_d6bda98bc5b74ca9a5ab476f0b7e2bdc"}},"99f89a8ad0b54d48bcd99f25c3b11fbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d3ea2da19ae4ffdbd6a93de9022b90b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b33198cbdf8347b69a13f5b86400db1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1d4c964a2154aa894a6c5a1754c9469":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c234bb1da0114bc58dbb5d767cd1eb37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc27b7c8c5f34d139127c997ab3792fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce5f2c1a19bf4c7ea358a8d6457ce9d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ad5f8bb95254ef281584ec5f97af3de","placeholder":"​","style":"IPY_MODEL_99f89a8ad0b54d48bcd99f25c3b11fbe","value":" 570/570 [00:00&lt;00:00, 20.4kB/s]"}},"d57bcaf3d3b247bb915ddb6b7b433171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c234bb1da0114bc58dbb5d767cd1eb37","placeholder":"​","style":"IPY_MODEL_b33198cbdf8347b69a13f5b86400db1c","value":"Downloading: 100%"}},"d6bda98bc5b74ca9a5ab476f0b7e2bdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e02df13a59e445c2a70010907998f3c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7a9bff02622434e9aa06dfc0e67afce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d57bcaf3d3b247bb915ddb6b7b433171","IPY_MODEL_ee332a8986d3483087e34c667ad602a0","IPY_MODEL_2a787c6219e04c389b8795b2585b51e6"],"layout":"IPY_MODEL_c1d4c964a2154aa894a6c5a1754c9469"}},"e81298b05159499cb654f800e9e8eb03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f699b137f59d4849aaa226e31455677c","placeholder":"​","style":"IPY_MODEL_5f4ead0496ac403d95fa16586dbebd17","value":" 420M/420M [00:06&lt;00:00, 69.4MB/s]"}},"ee332a8986d3483087e34c667ad602a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f8600a4abb94b0f9bbe3b3a5c90991a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e02df13a59e445c2a70010907998f3c3","value":28}},"f699b137f59d4849aaa226e31455677c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcda55f2d4c94318ad8a8d1c517a384e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
