{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JfgX6lC-CeEN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656549814052,"user_tz":-120,"elapsed":32103,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"1ac3b01f-93aa-46b9-e1a7-bcf16b039b03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 59.5 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 57.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 13.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n","Mounted at ./mydata\n"]}],"source":["!pip install transformers\n","from google.colab import drive\n","drive.mount('./mydata')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyzGkzsuHNAA"},"outputs":[],"source":["import sys\n","sys.path.append('./mydata/MyDrive/CSNLP_Project/Bert_model_COQA')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZAJcRiiEZqp"},"outputs":[],"source":["import collections\n","import glob\n","import os\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tqdm, trange\n","from transformers import (AdamW, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup, BertTokenizer, BertModel, BertConfig)\n","from data.processors.coqa import Extract_Features, Processor, Result\n","from data.processors.evaluate import CoQAEvaluator, parse_args\n","from data.processors.Bert_model import BertBaseUncasedModel, load_dataset, Write_predictions\n","\n","import torch\n","import csv\n","import numpy as np\n","\n","import json\n","\n","# locations\n","train_file=\"coqa-train-v1.0.json\"\n","predict_file=\"coqa-dev-v1.0.json\"\n","cur_path = os.getcwd()\n","output_directory = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models\"\n","input_dir = cur_path + \"/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data\"\n","# can use either BERT base or BERT large\n","pretrained_model=\"bert-base-uncased\"\n","# pretrained_model=\"bert-large-uncased\"\n","epochs = 4\n","evaluation_batch_size=16\n","train_batch_size=2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jx46LBgUCeEn"},"outputs":[],"source":["### train function\n","\n","def train(train_dataset, model, tokenizer, device, batch_size=train_batch_size):\n","\n","    train_sampler = RandomSampler(train_dataset) \n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","    t_total = len(train_dataloader) // 1 * epochs\n","\n","    # Preparing optimizer and scheduler\n","    \n","    optimizer_parameters = [{\"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])],\"weight_decay\": 0.01,},{\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])], \"weight_decay\": 0.0}]\n","    optimizer = AdamW(optimizer_parameters,lr=1e-5, eps=1e-8)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2000, num_training_steps=t_total)\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if os.path.isfile(os.path.join(pretrained_model, \"optimizer.pt\")) and os.path.isfile(os.path.join(pretrained_model, \"scheduler.pt\")):\n","        optimizer.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(\n","            os.path.join(pretrained_model, \"scheduler.pt\")))\n","\n","    counter = 1\n","    epochs_trained = 0\n","    train_loss, loss = 0.0, 0.0\n","    model.zero_grad()\n","    iterator = trange(epochs_trained, int(epochs), desc=\"Epoch\", disable=False)\n","    for _ in iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=True)\n","        for i,batch in enumerate(epoch_iterator):\n","            model.train()\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs = { \"input_ids\": batch[0],\"token_type_ids\": batch[1], \"attention_mask\": batch[2],\"start_positions\": batch[3],\"end_positions\": batch[4],\"rational_mask\": batch[5],\"cls_idx\": batch[6]}\n","            # loss = model(**inputs, return_dict=False)\n","            loss = model(**inputs)\n","            loss.backward()\n","            train_loss += loss.item()\n","\n","            #   optimizing training parameters\n","            if (i + 1) % 1 == 0:\n","                optimizer.step()\n","                scheduler.step()  \n","                model.zero_grad()\n","                counter += 1\n","                #   Saving model weights every 1000 iterations\n","                if counter % 1000 == 0:\n","                    output_dir = os.path.join(output_directory, \"model_weights\"+str(epochs_trained))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    model_to_save = model.module if hasattr(model, \"module\") else model\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","            if (i+1) % 1000 == 0:\n","                print('iter: {}, loss: {}'.format(i,train_loss/counter))\n","    return train_loss/counter"]},{"cell_type":"markdown","metadata":{"id":"n-avtGOw9JEV"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o4RsfgerCeEp","colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["3eff8b01882f455381049a32e1702718","fcbd0d13fb2d4ec6a97bf5712bf851ef","7a11502814a944a08fbff0f5870b1248","67504aa5859b4cdebdeb0e8a4b1029af","dbd27f88f6e7482184415534b032ec2a","2f59c4b05fac460ab99bc93238a14760","a8d2e8f9c27c414dae1dbeca9af3b68b","f762b8834c23443fbb9d49eb5395a409","318a46e10a4a41ff8af2ee222d9e05ee","d7f0c419d3e445f7b903814ac8b6634f","3adea48bcdf942d5a521e56f297d8693","3b73f32a404943088bba0a6a46b58a43","18263404617742af9264ec94ecb48d51","cfbcfc6566de40738c35b709520c6056","ec5f7ae733bc4da6a42dd35db2c680fc","7d57cb00c88f452f85ce334d311cf622","fbf4e0c2a1394bb0a65807328cb20c81","98314b556d214d928f961ed26b7c8c60","a544b4b73bab48e5ba9b3811e3c285ba","7c94fead9f824dbbba848b571a99310a","8707ac81fa764dd5b5f2351e17072b5e","d8d19b9e8ded48859ba8931474a8d570","eb53974097714f43b66b258238b9a1a2","d962c3d4af7d426aa6aa98185969f5ac","52e91fbc4e0b4f769eefb85f0dcbcc21","9967b0449bc54479869ec876ad10db48","47e99224d8554c06ae9f762e9be1b7dd","32fe215cb9ef4b338a44adf3dad69835","b9e0fc1dd604482aa0cde9ce7c5829cc","37c183339b2b4e3cb1c89e0a702d6022","f2dc566e546e423daed50d25b1062033","62a7031fdb5c47fcb3c4b1b7c6e901e3","4c00ea71bd6243e4a87efefba1a64064","79a01119b70b411599d2cda3cbe721a2","ef4f4f73fbdf41a4855004a20e045c0e","30cf0c9e9a3c488b8cb093e1d98b99a2","42e9f9a3defb41fba16ad3d831f0649a","738d6098a84b49a38128d98ef256138a","dc302568da294d469b211af28462c336","9afcb5077808434ba304390e30e822f8","def3bbb5c9334a87872aefae96eab5a1","11ccefdfd47245f6b49a142605211d97","06cbbcacb87140b2b60a322ab2a18324","2916d9ab49f24798aba92cf6c729ebcb"]},"outputId":"17f2b9cf-0a07-46d8-d4e1-3a20181b985c","executionInfo":{"status":"ok","timestamp":1656549999327,"user_tz":-120,"elapsed":147586,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eff8b01882f455381049a32e1702718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b73f32a404943088bba0a6a46b58a43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb53974097714f43b66b258238b9a1a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79a01119b70b411599d2cda3cbe721a2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertBaseUncasedModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertBaseUncasedModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertBaseUncasedModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertBaseUncasedModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['linear2.bias', 'fc.weight', 'linear1.weight', 'fc.bias', 'linear1.bias', 'linear2.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Loading cache /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/bert-base-uncased_train_with_T5_append_v3\n"]}],"source":["#   check if gpu is available to use it or not\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#   initialize configurations and tokenizer of Bert model \n","config = BertConfig.from_pretrained(pretrained_model, return_dict=False)\n","tokenizer = BertTokenizer.from_pretrained(pretrained_model)\n","\n","model = BertBaseUncasedModel.from_pretrained(pretrained_model, from_tf=bool(\".ckpt\" in pretrained_model), config=config,cache_dir=None,)\n","# print(model)\n","model.to(device)\n","\n","# if (os.path.exists(output_directory) and os.listdir(output_directory)):\n","#     raise ValueError(\"Output directory \" + output_directory + \" already exists, Change output_directory name\")\n","\n","method = 'append_v3'\n","\n","#   Loading dataset and training\n","# this command will take several hours\n","cache_file_name = 'bert-base-uncased_train_with_T5_{}'.format(method)\n","\n","train_file_name = 'coqa-train-v1.0-{}_with_T5.json'.format(method)\n","\n","train_dataset = load_dataset(tokenizer, input_dir=input_dir, evaluate=False, cache_file_name=cache_file_name, train_file_name=train_file_name, append_method='append')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fvKBU3GgCeEr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1656582773866,"user_tz":-120,"elapsed":32718198,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"972ddd64-8ed6-4847-a29a-480af76237b2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 5.534330590264304\n","iter: 1999, loss: 4.612942158788636\n","iter: 2999, loss: 4.009185854691896\n","iter: 3999, loss: 3.662777036461971\n","iter: 4999, loss: 3.4253794806757063\n","iter: 5999, loss: 3.243869761616821\n","iter: 6999, loss: 3.110814164858378\n","iter: 7999, loss: 3.0160852285010518\n","iter: 8999, loss: 2.939522956218498\n","iter: 9999, loss: 2.8644387045510706\n","iter: 10999, loss: 2.7954104693856916\n","iter: 11999, loss: 2.7375868615776526\n","iter: 12999, loss: 2.6830395460575787\n","iter: 13999, loss: 2.6429604820805475\n","iter: 14999, loss: 2.605320129833351\n","iter: 15999, loss: 2.5646783623616924\n","iter: 16999, loss: 2.5295751588175306\n","iter: 17999, loss: 2.4968746823730696\n","iter: 18999, loss: 2.4708228334980564\n","iter: 19999, loss: 2.4453890970007794\n","iter: 20999, loss: 2.4226710522723596\n","iter: 21999, loss: 2.400431343126333\n","iter: 22999, loss: 2.381803131874196\n","iter: 23999, loss: 2.363338503940188\n","iter: 24999, loss: 2.3450582661893917\n","iter: 25999, loss: 2.3271567143500853\n","iter: 26999, loss: 2.3097890795043883\n","iter: 27999, loss: 2.294480353837092\n","iter: 28999, loss: 2.27954090403874\n","iter: 29999, loss: 2.2637380182759586\n","iter: 30999, loss: 2.250901870375501\n","iter: 31999, loss: 2.2403363604587487\n","iter: 32999, loss: 2.2302305153379307\n","iter: 33999, loss: 2.2183104566948715\n","iter: 34999, loss: 2.208669211005067\n","iter: 35999, loss: 2.200457066952181\n","iter: 36999, loss: 2.1893331148519186\n","iter: 37999, loss: 2.1778374542421783\n","iter: 38999, loss: 2.167470064090563\n","iter: 39999, loss: 2.156784931369308\n","iter: 40999, loss: 2.149280706324594\n","iter: 41999, loss: 2.1405025765512047\n","iter: 42999, loss: 2.131487654932007\n","iter: 43999, loss: 2.122773704639984\n","iter: 44999, loss: 2.1152588081313324\n","iter: 45999, loss: 2.1080478780696477\n","iter: 46999, loss: 2.1018738348071246\n","iter: 47999, loss: 2.0958348329864602\n","iter: 48999, loss: 2.089145596979948\n","iter: 49999, loss: 2.0824565628239107\n","iter: 50999, loss: 2.0745559919691843\n","iter: 51999, loss: 2.0677156465535007\n","iter: 52999, loss: 2.0603735330307\n","iter: 53999, loss: 2.0547405238208136\n","iter: 54999, loss: 2.0490864471705574\n","iter: 55999, loss: 2.043318346949313\n","iter: 56999, loss: 2.0380631817389054\n","iter: 57999, loss: 2.0320031354589347\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  25%|██▌       | 1/4 [2:16:12<6:48:37, 8172.60s/it]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 2.0204209006893445\n","iter: 1999, loss: 2.009793155685561\n","iter: 2999, loss: 1.9999774383013789\n","iter: 3999, loss: 1.9893540299420165\n","iter: 4999, loss: 1.9796044508729582\n","iter: 5999, loss: 1.970821045383605\n","iter: 6999, loss: 1.962384112931296\n","iter: 7999, loss: 1.9537948067869786\n","iter: 8999, loss: 1.9456438214456107\n","iter: 9999, loss: 1.9375524130782285\n","iter: 10999, loss: 1.9296165236171765\n","iter: 11999, loss: 1.9217074483372172\n","iter: 12999, loss: 1.914139025846377\n","iter: 13999, loss: 1.9073028361045397\n","iter: 14999, loss: 1.899633842230647\n","iter: 15999, loss: 1.8925929407630706\n","iter: 16999, loss: 1.8857110979473701\n","iter: 17999, loss: 1.8801192064412016\n","iter: 18999, loss: 1.8725199881965862\n","iter: 19999, loss: 1.865830269999906\n","iter: 20999, loss: 1.8605581248173186\n","iter: 21999, loss: 1.8543536003028525\n","iter: 22999, loss: 1.8481397813070675\n","iter: 23999, loss: 1.8434914552822148\n","iter: 24999, loss: 1.8381148496849282\n","iter: 25999, loss: 1.8329053248981735\n","iter: 26999, loss: 1.8274648488837444\n","iter: 27999, loss: 1.8225417246103215\n","iter: 28999, loss: 1.8168740229143172\n","iter: 29999, loss: 1.8126982558937\n","iter: 30999, loss: 1.8079203468947047\n","iter: 31999, loss: 1.802979746610917\n","iter: 32999, loss: 1.7988111332703247\n","iter: 33999, loss: 1.794196951835957\n","iter: 34999, loss: 1.7894901863805734\n","iter: 35999, loss: 1.784821608123796\n","iter: 36999, loss: 1.7800548463727555\n","iter: 37999, loss: 1.7763481523634983\n","iter: 38999, loss: 1.771775749920553\n","iter: 39999, loss: 1.7678173198665268\n","iter: 40999, loss: 1.7640257789608618\n","iter: 41999, loss: 1.7599843380789262\n","iter: 42999, loss: 1.7566511063266035\n","iter: 43999, loss: 1.7525022530766623\n","iter: 44999, loss: 1.74902122634289\n","iter: 45999, loss: 1.745557528751125\n","iter: 46999, loss: 1.7417324039356652\n","iter: 47999, loss: 1.7377041666035211\n","iter: 48999, loss: 1.7342379049880827\n","iter: 49999, loss: 1.729915784475372\n","iter: 50999, loss: 1.7265257718886473\n","iter: 51999, loss: 1.723117540379116\n","iter: 52999, loss: 1.7191853587357266\n","iter: 53999, loss: 1.7159309220728995\n","iter: 54999, loss: 1.7129443787596321\n","iter: 55999, loss: 1.7091047736334257\n","iter: 56999, loss: 1.7060274040766212\n","iter: 57999, loss: 1.7029183531032195\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 2/4 [4:32:40<4:32:42, 8181.36s/it]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 1.69631037358621\n","iter: 1999, loss: 1.6904607630284447\n","iter: 2999, loss: 1.6845267113782736\n","iter: 3999, loss: 1.679178306212073\n","iter: 4999, loss: 1.673294792580037\n","iter: 5999, loss: 1.6679533197350254\n","iter: 6999, loss: 1.6627272167166947\n","iter: 7999, loss: 1.6572534811397512\n","iter: 8999, loss: 1.6520547789642293\n","iter: 9999, loss: 1.6476634282490485\n","iter: 10999, loss: 1.6429638106537245\n","iter: 11999, loss: 1.6379335022317671\n","iter: 12999, loss: 1.6329209209084137\n","iter: 13999, loss: 1.6279475152427225\n","iter: 14999, loss: 1.6231259257486235\n","iter: 15999, loss: 1.6191201792204413\n","iter: 16999, loss: 1.6144210841546125\n","iter: 17999, loss: 1.6103958753089584\n","iter: 18999, loss: 1.6059721492108543\n","iter: 19999, loss: 1.6016478396314977\n","iter: 20999, loss: 1.5973673537698785\n","iter: 21999, loss: 1.5928089107835712\n","iter: 22999, loss: 1.5887607175443244\n","iter: 23999, loss: 1.5839888912768365\n","iter: 24999, loss: 1.5800596005026073\n","iter: 25999, loss: 1.5759563808548072\n","iter: 26999, loss: 1.5717058861883137\n","iter: 27999, loss: 1.5675490132911514\n","iter: 28999, loss: 1.5633156945734221\n","iter: 29999, loss: 1.559167332350903\n","iter: 30999, loss: 1.5556963031453217\n","iter: 31999, loss: 1.551824905619192\n","iter: 32999, loss: 1.5483962692603084\n","iter: 33999, loss: 1.5448724767242328\n","iter: 34999, loss: 1.5417395584577827\n","iter: 35999, loss: 1.538285953561692\n","iter: 36999, loss: 1.534748783589514\n","iter: 37999, loss: 1.531268694452623\n","iter: 38999, loss: 1.5277172624441988\n","iter: 39999, loss: 1.5243262856864355\n","iter: 40999, loss: 1.5207188367996134\n","iter: 41999, loss: 1.5172003676587644\n","iter: 42999, loss: 1.5139043796038578\n","iter: 43999, loss: 1.5106083683071732\n","iter: 44999, loss: 1.507741372158602\n","iter: 45999, loss: 1.5044121028571669\n","iter: 46999, loss: 1.5015415392587985\n","iter: 47999, loss: 1.4984705525878885\n","iter: 48999, loss: 1.495528363324981\n","iter: 49999, loss: 1.4924465602982886\n","iter: 50999, loss: 1.4896027492780717\n","iter: 51999, loss: 1.4864416501364286\n","iter: 52999, loss: 1.4834574422808848\n","iter: 53999, loss: 1.480511748935659\n","iter: 54999, loss: 1.4777248033009431\n","iter: 55999, loss: 1.474804664756792\n","iter: 56999, loss: 1.4721110081980193\n","iter: 57999, loss: 1.4694785673270208\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  75%|███████▌  | 3/4 [6:49:00<2:16:20, 8180.87s/it]"]},{"output_type":"stream","name":"stdout","text":["iter: 999, loss: 1.4651651010605862\n","iter: 1999, loss: 1.4612195071991754\n","iter: 2999, loss: 1.4570542255345789\n","iter: 3999, loss: 1.4530731661535334\n","iter: 4999, loss: 1.4488740111356557\n","iter: 5999, loss: 1.445041360735305\n","iter: 6999, loss: 1.4409990260432393\n","iter: 7999, loss: 1.436763393734759\n","iter: 8999, loss: 1.4331359558361665\n","iter: 9999, loss: 1.4294736093959317\n","iter: 10999, loss: 1.4258694337345565\n","iter: 11999, loss: 1.422256379403349\n","iter: 12999, loss: 1.4186747582087615\n","iter: 13999, loss: 1.4152375781705535\n","iter: 14999, loss: 1.411870431395917\n","iter: 15999, loss: 1.4084814635835097\n","iter: 16999, loss: 1.4048775305661843\n","iter: 17999, loss: 1.4013662881037159\n","iter: 18999, loss: 1.3981365594614672\n","iter: 19999, loss: 1.3946905636789306\n","iter: 20999, loss: 1.3912903938360635\n","iter: 21999, loss: 1.3879707582652174\n","iter: 22999, loss: 1.3847078107286177\n","iter: 23999, loss: 1.381617714969212\n","iter: 24999, loss: 1.3782641632040438\n","iter: 25999, loss: 1.3748218361990743\n","iter: 26999, loss: 1.371684305994542\n","iter: 27999, loss: 1.3686306622132238\n","iter: 28999, loss: 1.365520869337359\n","iter: 29999, loss: 1.3623171238169358\n","iter: 30999, loss: 1.359323382456074\n","iter: 31999, loss: 1.3562220365726865\n","iter: 32999, loss: 1.3530705611727787\n","iter: 33999, loss: 1.3502626576158256\n","iter: 34999, loss: 1.3473287808245538\n","iter: 35999, loss: 1.3444774169580256\n","iter: 36999, loss: 1.3415970567252191\n","iter: 37999, loss: 1.3385739065591606\n","iter: 38999, loss: 1.3357471614882301\n","iter: 39999, loss: 1.3331174165903588\n","iter: 40999, loss: 1.3303500120904195\n","iter: 41999, loss: 1.3275685013655052\n","iter: 42999, loss: 1.3248866234494707\n","iter: 43999, loss: 1.322103408467204\n","iter: 44999, loss: 1.319340756291325\n","iter: 45999, loss: 1.3165699930857377\n","iter: 46999, loss: 1.3136922722152147\n","iter: 47999, loss: 1.311047551965092\n","iter: 48999, loss: 1.3084137425919264\n","iter: 49999, loss: 1.3057018820608206\n","iter: 50999, loss: 1.3033109125001012\n","iter: 51999, loss: 1.3009994404460916\n","iter: 52999, loss: 1.2987197089807085\n","iter: 53999, loss: 1.2960748525153\n","iter: 54999, loss: 1.2933694072301494\n","iter: 55999, loss: 1.2907318343831853\n","iter: 56999, loss: 1.2882744984136878\n","iter: 57999, loss: 1.2856450711574385\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 4/4 [9:05:15<00:00, 8178.97s/it]\n"]},{"output_type":"execute_result","data":{"text/plain":["('/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v3/tokenizer_config.json',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v3/special_tokens_map.json',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v3/vocab.txt',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v3/added_tokens.json')"]},"metadata":{},"execution_count":6}],"source":["# train the model on CoQA\n","train_loss = train(train_dataset, model, tokenizer, device)\n","\n","variant_name = 'Bert_with_T5_rewritten_epoch4_append_v3'\n","\n","#   create output directory for model parameters and to write predictions\n","if not os.path.exists(output_directory+'/'+variant_name) :\n","    os.makedirs(output_directory+'/'+variant_name)\n","            \n","model_to_save = model.module if hasattr(model, \"module\") else model\n","model_to_save.save_pretrained(output_directory+'/'+variant_name)\n","tokenizer.save_pretrained(output_directory+'/'+variant_name)"]},{"cell_type":"markdown","metadata":{"id":"XDyYsqyW9JEY"},"source":["## Prediction\n","\n","predict on dev dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F_1nMH-SIivu"},"outputs":[],"source":["#   check if gpu is available to use it or not\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","#   Loading Bert model for writing predictions\n","# model = BertBaseUncasedModel.from_pretrained(output_directory)\n","# tokenizer = BertTokenizer.from_pretrained(output_directory, do_lower_case=True)\n","# model.to(device)\n","# run for different parameters\n","\n","# check if gpu is available to use it or not\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","# for m in model_parameter_directory:\n","#     variant_name = m.split('/')[-1]\n","#     model = BertBaseUncasedModel.from_pretrained(m) \n","#     tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","#     model.to(device)\n","#     Write_predictions(model, tokenizer, device, variant_name)\n","# train_dataset = load_dataset(tokenizer, evaluate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1656231737861,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"g6PF9-kg9pvR","outputId":"7952ac83-3a9f-450a-a6a1-44ee668f23b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_from_original_Surya_epoch4',\n"," '/content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/Bert_models/Bert_with_T5_rewritten_epoch4_append_v2']"]},"metadata":{},"execution_count":8}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","cache_file_name = 'bert-base-uncased_dev_with_T5_append'\n","\n","train_file_name = 'coqa-dev-v1.0.json'\n","\n","model_parameter_directory"]},{"cell_type":"code","source":["# for m in model_parameter_directory:\n","m = model_parameter_directory[1]\n","variant_name = m.split('/')[-1]\n","# m = m + '/pytorch_model_2.bin'\n","model = BertBaseUncasedModel.from_pretrained(m) \n","tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","model.to(device)\n","Write_predictions(model, tokenizer, device, variant_name, input_dir=input_dir, output_directory=output_directory, cache_file_name=cache_file_name, predict_file_name=None)"],"metadata":{"id":"uOOl8SQ2s02q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655734894838,"user_tz":-120,"elapsed":236667,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"}},"outputId":"7b918754-f4e4-4293-e2da-26100a9b1ca1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading cache /content/mydata/MyDrive/CSNLP_Project/Bert_model_COQA/data/bert-base-uncased_dev_with_T5_append\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating: 100%|██████████| 8775/8775 [03:14<00:00, 45.15it/s]\n","Writing preditions: 100%|██████████| 7983/7983 [00:28<00:00, 284.79it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"L_AFYP9k0Yu1"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VY9u1rP0cSu"},"outputs":[],"source":["evaluator = CoQAEvaluator(input_dir+'/'+predict_file)\n","\n","variant_name = 'Bert_from_original_Surya_epoch4'\n","\n","pre_file_bert = output_directory+'/'+variant_name+'/'+'predictions.json'\n","\n","# evaluate\n","with open(pre_file_bert) as f:\n","    pred_data = CoQAEvaluator.preds_to_dict(pre_file_bert)\n","\n","# write evaluate result\n","with open(output_directory+'/'+variant_name+'/'+'evaluation.json', 'w') as f:\n","    json.dump(evaluator.model_performance(pred_data), f, indent=2)\n","\n","# show\n","# print(json.dumps(evaluator.model_performance(pred_data), indent=2))"]},{"cell_type":"markdown","metadata":{"id":"QZt4mghfQyTj"},"source":["get_domain_scores --> model_performance --> get_raw_scores --> compute_turn_score --> _compute_turn_score --> compute_exact /  compute_f1\n"]},{"cell_type":"markdown","metadata":{"id":"N_xpwsOQpiva"},"source":["## Test any input on the fine-tuned model: By ZYZ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_EAPoJPZAequ"},"outputs":[],"source":["### this cell load the fine tuned model\n","\n","# check if gpu is available to use it or not\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model_parameter_directory = [ f.path for f in os.scandir(output_directory) if f.is_dir() ]\n","\n","for m in model_parameter_directory:\n","    variant_name = m.split('/')[-1]\n","    model = BertBaseUncasedModel.from_pretrained(m) \n","    tokenizer = BertTokenizer.from_pretrained(m, do_lower_case=True)\n","    model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7961,"status":"ok","timestamp":1652290735026,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"Zy243hvSJv_J","outputId":"72eeff4e-6a9b-49a5-995e-a29851da5c20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading cache /content/mydata/MyDrive/Colab Notebooks/data/bert-base-uncased_dev_test\n"]}],"source":["### load the dev dataset with gold answer\n","\n","cache_file = os.path.join(input_dir,\"bert-base-uncased_dev_test\")\n","\n","if os.path.exists(cache_file):\n","    print(\"Loading cache\",cache_file)\n","    features_and_dataset = torch.load(cache_file)\n","    features, dataset, examples = (\n","        features_and_dataset[\"features\"],features_and_dataset[\"dataset\"],features_and_dataset[\"examples\"])\n","else:\n","    print(\"Creating features from dataset file at\", input_dir)\n","\n","    processor = Processor()\n","\n","    examples = processor.get_examples(input_dir, 2, filename=predict_file, threads=1)\n","\n","    # max_seq_length is the total length for input sequence of BERT \n","    features, dataset = Extract_Features(examples=examples,tokenizer=tokenizer,max_seq_length=512, doc_stride=128, max_query_length=64, is_training=True, threads=1)\n","    #   caching it in a cache file to reduce time\n","    torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cache_file)\n","\n","# create evaluation_test_dataloader\n","evalutation_test_sampler = SequentialSampler(dataset)\n","evaluation_test_dataloader = DataLoader(dataset, sampler=evalutation_test_sampler, batch_size=1)\n"]},{"cell_type":"markdown","metadata":{"id":"d_yk1-jrRIug"},"source":["1. model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n","2. torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fa8h6OX1F0r"},"outputs":[],"source":["def predict(batch):\n","  '''\n","  given input_ids of text, QA history and current question, predict answer with \n","  model and compare with ground truth answer span\n","  '''\n","  model.eval()\n","  batch = tuple(t.to(device) for t in batch)\n","  with torch.no_grad():\n","      inputs = {\"input_ids\": batch[0],\"token_type_ids\": batch[1],\"attention_mask\": batch[2]}\n","      inputs_text = inputs[\"input_ids\"]\n","      outputs = model(**inputs)\n","\n","  # convert ids to texts\n","  input_ids = inputs_text[0]\n","  # tokens are all QA and text\n","  tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","  # sep_idx = list(input_ids).index(tokenizer.sep_token_id)\n","  # question = \" \".join(tokens[:(sep_idx+1)])\n","  # sep_idx2 = list(input_ids[(sep_idx+1):]).index(tokenizer.sep_token_id)\n","  # text = \" \".join(tokens[(sep_idx+1):(sep_idx2+(sep_idx+1))])\n","\n","  def convert_to_list(tensor):\n","      return tensor.detach().cpu().tolist()\n","      \n","  # extract answer from prediction of bert\n","  output = [convert_to_list(output[0]) for output in outputs]\n","  start_logits, end_logits, yes_logits, no_logits, unk_logits = output\n","  start_pos = np.argmax(start_logits)\n","  end_pos = np.argmax(end_logits)\n","\n","  print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n","  answer = \" \".join(tokens[start_pos:end_pos+1])\n","  print(\"Answer:\\n{}.\".format(answer.capitalize()))\n","\n","  # pass"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":226,"status":"ok","timestamp":1652291599956,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"hgpVaVcbk5oq","outputId":"50c69034-edd3-44b8-cba6-a38082ac1f73"},"outputs":[{"name":"stdout","output_type":"stream","text":["question: [CLS] where did she live ? in a barn [SEP] did she live alone ? no [SEP] who did she live with ? [SEP] \n","\n"," text: upon a time , in a barn near a farm house , there lived a little white kitten named cotton . cotton lived high up in a nice warm place above the barn where all of the farmer ' s horses slept . but cotton was n ' t alone in her little home above the barn , oh no . she shared her hay bed with her mommy and 5 other sisters . all of her sisters were cute and fluffy , like cotton . but she was the only white one in the bunch . the rest of her sisters were all orange with beautiful white tiger stripes like cotton ' s mommy . being different made cotton quite sad . she often wished she looked like the rest of her family . so one day , when cotton found a can of the old farmer ' s orange paint , she used it to paint herself like them . when her mommy and sisters found her they started laughing . \" what are you doing , cotton ? ! \" \" i only wanted to be more like you \" . cotton ' s mommy rubbed her face on cotton ' s and said \" oh cotton , but your fur is so pretty and special , like you . we would never want you to be any other way \" . and with that , cotton ' s mommy picked her up and dropped her into a big bucket of water . when cotton came out she was herself again . her sisters licked her face until cotton ' s fur was all all dry . \" do n ' t ever do that again , cotton ! \" they all cried . \" next time you might mess up that pretty white fur of yours and we would n ' t want that ! \" then cotton thought , \" i change my mind . i like being special \" . \n","\n"," gold answer: with her mommy and 5 other sisters\n"]}],"source":["random_num = np.random.randint(0,len(evaluation_test_dataloader))\n","random_num = 3\n","\n","## evaluation_test_dataloader is not iteratable\n","## dummy method\n","count = 0\n","for batch in evaluation_test_dataloader:\n","    # print(len(batch[3]))\n","    if count >= random_num:\n","        break\n","    count += 1\n","\n","# data from batch\n","input_ids = batch[0][0]\n","token_type_ids = batch[1][0]\n","tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","# sep_idx = list(input_ids).index(tokenizer.sep_token_id)\n","sep_idx = torch.where(token_type_ids==1)[0][0]\n","question = \" \".join(tokens[:(sep_idx)])\n","sep_idx2 = list(input_ids[(sep_idx+1):]).index(tokenizer.sep_token_id)\n","text = \" \".join(tokens[(sep_idx+1):(sep_idx2+(sep_idx+1))])\n","\n","# extract gold answer\n","start_positions = batch[3][0]\n","end_positions = batch[4][0]\n","gold_answer = \" \".join(tokens[start_positions:end_positions+1])\n","\n","print('question: '+question,'\\n\\n','text: '+text,'\\n\\n','gold answer: '+gold_answer)#+data[\"answer\"][random_num])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1652291603571,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"z-1792vrN2hg","outputId":"946f244d-b798-4b70-cd90-6246ce9164b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Question:\n","[cls] where did she live ? in a barn [sep] did she live alone ? no [sep] who did she live with ? [sep]\n","Answer:\n","Her mommy and 5 other sisters.\n"]}],"source":["predict(batch)"]},{"cell_type":"markdown","metadata":{"id":"2JKyB4a6i0oh"},"source":["## Write all the failure cases"]},{"cell_type":"markdown","metadata":{"id":"EQpQpvMfRvOW"},"source":["#### Use evaluator.compute_turn_score to evaluate each case\n","\n","e.g.\n","\n","evaluator.compute_turn_score('3dr23u6we5exclen4th8uq9rb42tel', 4, 'her mommy and 5 other sisters')\n","\n","output: {'em': 1.0, 'f1': 1.0} (exact match and f1 score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gAzZ2Tdiu_Y"},"outputs":[],"source":["# failure criteria\n","criteria_flag = 'full'\n","\n","# tuples for all prediction data\n","pre_data_list = []\n","for key in pred_data.keys():\n","    pre_data_list.append(key + (pred_data[key],) )\n","\n","# find out all the failure cases: their ids\n","fail_results = []\n","for prediction in pre_data_list:\n","    result = evaluator.compute_turn_score(prediction[0],prediction[1],prediction[2])\n","    # totally wrong\n","    if criteria_flag == 'full':\n","        if result == {'em': 0.0, 'f1': 0.0}:\n","            fail_results.append(prediction)\n","    # not fully correct\n","    elif criteria_flag == 'partial':\n","        if result != {'em': 1.0, 'f1': 1.0}:\n","            fail_results.append(prediction)\n","    # print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1652301186201,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"JJ5Jc5XUz9PU","outputId":"10ad3d83-4b0e-41cb-fdde-eacf2ac23b6d"},"outputs":[{"data":{"text/plain":["0.1663535011900288"]},"execution_count":130,"metadata":{},"output_type":"execute_result"}],"source":["len(fail_results) / len(pre_data_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jrOrErxuixSk"},"outputs":[],"source":["# write results\n","with open(output_directory+'/'+variant_name+'/'+'fully_failed_predictions.csv', mode='w+', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.writer(f)\n","    writer.writerow(['passage_id','turn_id','story_type', 'story', 'history QA', 'current question', 'gold_answers', 'failed_prediction', 'scores'])\n","\n","with open(output_directory+'/'+variant_name+'/'+'fully_failed_predictions.csv', mode='a+', encoding='utf-8-sig', newline='') as f:\n","    writer = csv.writer(f)\n","    \n","    for fail_result in fail_results:\n","        story_id = fail_result[0]\n","        turn_id = fail_result[1]\n","        key = (story_id, turn_id)\n","        a_gold_list = evaluator.gold_data[key]\n","        scores = evaluator.compute_turn_score(fail_result[0],fail_result[1],fail_result[2])\n","        # evaluator.questions[turn_id]\n","        writer.writerow([story_id,turn_id,evaluator.id_to_source[story_id],evaluator.story_dict[story_id],\\\n","                         evaluator.question_dict[story_id][:turn_id-1],evaluator.question_dict[story_id][turn_id-1],a_gold_list, fail_result[2], scores])\n"]},{"cell_type":"markdown","metadata":{"id":"utcqU6v9xJva"},"source":["### Test results of yes/no answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzxs27q3xN0R"},"outputs":[],"source":["# tuples for all prediction data\n","yn_data_list = []\n","for key in pred_data.keys():\n","    if pred_data[key] in ['yes','no']:\n","        yn_data_list.append(key + (pred_data[key],) )\n","\n","\n","# find out all the failure cases: their ids\n","yn_fail_results = []\n","for prediction in yn_data_list:\n","    result = evaluator.compute_turn_score(prediction[0],prediction[1],prediction[2])\n","    # not fully correct\n","    # if result != {'em': 1.0, 'f1': 1.0}:\n","    # totally wrong\n","    if result == {'em': 0.0, 'f1': 0.0}:\n","        yn_fail_results.append(prediction)\n","    # print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1652301233734,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"dtBu46GBzQlL","outputId":"3d32d9a5-a928-45cb-f8c7-a12c6abcde45"},"outputs":[{"data":{"text/plain":["0.22059376174370537"]},"execution_count":133,"metadata":{},"output_type":"execute_result"}],"source":["yn_ratio = len(yn_data_list) / len(pred_data)\n","yn_ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1652301372268,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"K10NZwq81Wgr","outputId":"d68c3d5d-27e3-47bd-9cb9-0e0f724b6e45"},"outputs":[{"data":{"text/plain":["0.1486660237865638"]},"execution_count":135,"metadata":{},"output_type":"execute_result"}],"source":["non_yn_failure_ratio = (len(fail_results)-len(yn_fail_results)) / (len(pre_data_list)-len(yn_data_list))\n","non_yn_failure_ratio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1652301254288,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"LDQOn2EPzSDr","outputId":"917616ea-d4c6-4db8-eda5-b02196f9ae1a"},"outputs":[{"data":{"text/plain":["0.22884724588302102"]},"execution_count":134,"metadata":{},"output_type":"execute_result"}],"source":["yn_failure_ratio = len(yn_fail_results) / len(yn_data_list)\n","yn_failure_ratio"]},{"cell_type":"markdown","metadata":{"id":"kZTdQd0x1G9x"},"source":["Observation: The fully wrong ({'em': 0.0, 'f1': 0.0}) ratio of yes/no type question is higher then the normal question.\n","\n","\n","Need to construct a dictionary for computing the overall F1 score of these two different type of questions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWGdX5rdz4CB"},"outputs":[],"source":["# tuples for all prediction data\n","yn_dict = {}\n","non_yn_dict = {}\n","yn_turns  = {}\n","for i in list(domain_mappings.values()):\n","    yn_turns[i] = 0\n","    \n","for key in pred_data.keys():\n","    if pred_data[key] in ['yes','no']:\n","        story_type = evaluator.id_to_source[key[0]]\n","        yn_turns[domain_mappings[story_type]] += 1\n","        yn_dict[key] = pred_data[key]\n","    else:\n","        non_yn_dict[key] = pred_data[key]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652302902453,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"sms4ulTb67UH","outputId":"a7c53c24-0a2e-4159-9d4c-9c61399ea614"},"outputs":[{"data":{"text/plain":["['children_stories',\n"," 'literature',\n"," 'mid-high_school',\n"," 'news',\n"," 'wikipedia',\n"," 'science',\n"," 'reddit']"]},"execution_count":162,"metadata":{},"output_type":"execute_result"}],"source":["list(domain_mappings.values())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652302594220,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"dKm0KKbU6LmW","outputId":"51ccad7f-b8fd-4441-bc37-1d9e1aa0235f"},"outputs":[{"data":{"text/plain":["290"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["yn_turns[story_type]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":970,"status":"ok","timestamp":1652303069989,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"e9hYB58U2TSO","outputId":"7b878721-8e5b-4db1-bb14-e332e1761ada"},"outputs":[{"name":"stdout","output_type":"stream","text":["no yes/no answer in reddit\n","no yes/no answer in science\n"]}],"source":["# evaluator.model_performance(yn_dict)\n","result_yn = json.dumps(evaluator.model_performance(yn_dict), indent=2)\n","result_yn = json.loads(result_yn)\n","for case in result_yn:\n","    if case not in ['in_domain', 'out_domain','overall']:\n","        if yn_turns[case] == 0:\n","            print('no yes/no answer in {}'.format(case))\n","            pass\n","        else:\n","            result_yn[case]['em'] = result_yn[case]['em'] * result_yn[case]['turns'] / yn_turns[case]\n","            result_yn[case]['f1'] = result_yn[case]['f1'] * result_yn[case]['turns'] / yn_turns[case]\n","            result_yn[case]['turns'] = yn_turns[case]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1652303081553,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"6qSJkOVz8BB3","outputId":"85d37883-39da-49f1-b77b-7288e4501cd2"},"outputs":[{"data":{"text/plain":["{'children_stories': {'em': 74.27762039660055,\n","  'f1': 74.27762039660055,\n","  'turns': 353},\n"," 'in_domain': {'em': 16.8, 'f1': 16.8, 'turns': 7983},\n"," 'literature': {'em': 74.05432098765431,\n","  'f1': 74.05432098765431,\n","  'turns': 405},\n"," 'mid-high_school': {'em': 75.67442455242966,\n","  'f1': 75.67442455242966,\n","  'turns': 391},\n"," 'news': {'em': 78.35310559006211, 'f1': 78.35310559006211, 'turns': 322},\n"," 'out_domain': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'overall': {'em': 16.8, 'f1': 16.8, 'turns': 7983},\n"," 'reddit': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'science': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'wikipedia': {'em': 80.17862068965518, 'f1': 80.17862068965518, 'turns': 290}}"]},"execution_count":169,"metadata":{},"output_type":"execute_result"}],"source":["result_yn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3924,"status":"ok","timestamp":1652303205897,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"NicPvA_s7l6p","outputId":"4ad2cee6-5e96-4007-d613-80ea5357da35"},"outputs":[{"name":"stdout","output_type":"stream","text":["no yes/no answer in reddit\n","no yes/no answer in science\n"]}],"source":["# evaluator.model_performance(yn_dict)\n","result_non_yn = json.dumps(evaluator.model_performance(non_yn_dict), indent=2)\n","result_non_yn = json.loads(result_non_yn)\n","for case in result_non_yn:\n","    if case not in ['in_domain', 'out_domain','overall']:\n","        if yn_turns[case] == result_non_yn[case]['turns']:\n","            print('no yes/no answer in {}'.format(case))\n","            pass\n","        else:\n","            result_non_yn[case]['em'] = result_non_yn[case]['em'] * result_non_yn[case]['turns'] / (result_non_yn[case]['turns']-yn_turns[case])\n","            result_non_yn[case]['f1'] = result_non_yn[case]['f1'] * result_non_yn[case]['turns'] / (result_non_yn[case]['turns']-yn_turns[case])\n","            result_non_yn[case]['turns'] = (result_non_yn[case]['turns']-yn_turns[case])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1652303212473,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"SUMq025_4CMy","outputId":"1022d8ac-0744-43d9-dac5-25f93289f5d2"},"outputs":[{"data":{"text/plain":["{'children_stories': {'em': 60.748600746268664,\n","  'f1': 73.64272388059702,\n","  'turns': 1072},\n"," 'in_domain': {'em': 48.1, 'f1': 58.1, 'turns': 7983},\n"," 'literature': {'em': 58.81306122448979,\n","  'f1': 71.98612244897959,\n","  'turns': 1225},\n"," 'mid-high_school': {'em': 57.63232963549921,\n","  'f1': 71.25451664025357,\n","  'turns': 1262},\n"," 'news': {'em': 63.62381311228335, 'f1': 76.92019593067067, 'turns': 1327},\n"," 'out_domain': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'overall': {'em': 48.1, 'f1': 58.1, 'turns': 7983},\n"," 'reddit': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'science': {'em': 0.0, 'f1': 0.0, 'turns': 0},\n"," 'wikipedia': {'em': 67.4254491017964, 'f1': 78.37904191616767, 'turns': 1336}}"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["result_non_yn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4786,"status":"ok","timestamp":1652303268221,"user":{"displayName":"Mr. Z","userId":"12849447431415807254"},"user_tz":-120},"id":"RQEzPaf04E59","outputId":"ca75b98c-5360-4f85-bd74-591582be8141"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"children_stories\": {\n","    \"em\": 64.1,\n","    \"f1\": 73.8,\n","    \"turns\": 1425\n","  },\n","  \"literature\": {\n","    \"em\": 62.5,\n","    \"f1\": 72.5,\n","    \"turns\": 1630\n","  },\n","  \"mid-high_school\": {\n","    \"em\": 61.9,\n","    \"f1\": 72.3,\n","    \"turns\": 1653\n","  },\n","  \"news\": {\n","    \"em\": 66.6,\n","    \"f1\": 77.2,\n","    \"turns\": 1649\n","  },\n","  \"wikipedia\": {\n","    \"em\": 69.6,\n","    \"f1\": 78.7,\n","    \"turns\": 1626\n","  },\n","  \"reddit\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"science\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"in_domain\": {\n","    \"em\": 65.0,\n","    \"f1\": 74.9,\n","    \"turns\": 7983\n","  },\n","  \"out_domain\": {\n","    \"em\": 0.0,\n","    \"f1\": 0.0,\n","    \"turns\": 0\n","  },\n","  \"overall\": {\n","    \"em\": 65.0,\n","    \"f1\": 74.9,\n","    \"turns\": 7983\n","  }\n","}\n"]}],"source":["print(json.dumps(evaluator.model_performance(pred_data), indent=2))"]},{"cell_type":"markdown","metadata":{"id":"4B63hRUr81dG"},"source":["so the actuall overall f1 score for yes/no question is higher"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Bert_convqa_with_evaluate.ipynb","provenance":[]},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"3eff8b01882f455381049a32e1702718":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fcbd0d13fb2d4ec6a97bf5712bf851ef","IPY_MODEL_7a11502814a944a08fbff0f5870b1248","IPY_MODEL_67504aa5859b4cdebdeb0e8a4b1029af"],"layout":"IPY_MODEL_dbd27f88f6e7482184415534b032ec2a"}},"fcbd0d13fb2d4ec6a97bf5712bf851ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f59c4b05fac460ab99bc93238a14760","placeholder":"​","style":"IPY_MODEL_a8d2e8f9c27c414dae1dbeca9af3b68b","value":"Downloading: 100%"}},"7a11502814a944a08fbff0f5870b1248":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f762b8834c23443fbb9d49eb5395a409","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_318a46e10a4a41ff8af2ee222d9e05ee","value":570}},"67504aa5859b4cdebdeb0e8a4b1029af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7f0c419d3e445f7b903814ac8b6634f","placeholder":"​","style":"IPY_MODEL_3adea48bcdf942d5a521e56f297d8693","value":" 570/570 [00:00&lt;00:00, 22.3kB/s]"}},"dbd27f88f6e7482184415534b032ec2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f59c4b05fac460ab99bc93238a14760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d2e8f9c27c414dae1dbeca9af3b68b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f762b8834c23443fbb9d49eb5395a409":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"318a46e10a4a41ff8af2ee222d9e05ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7f0c419d3e445f7b903814ac8b6634f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3adea48bcdf942d5a521e56f297d8693":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b73f32a404943088bba0a6a46b58a43":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18263404617742af9264ec94ecb48d51","IPY_MODEL_cfbcfc6566de40738c35b709520c6056","IPY_MODEL_ec5f7ae733bc4da6a42dd35db2c680fc"],"layout":"IPY_MODEL_7d57cb00c88f452f85ce334d311cf622"}},"18263404617742af9264ec94ecb48d51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf4e0c2a1394bb0a65807328cb20c81","placeholder":"​","style":"IPY_MODEL_98314b556d214d928f961ed26b7c8c60","value":"Downloading: 100%"}},"cfbcfc6566de40738c35b709520c6056":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a544b4b73bab48e5ba9b3811e3c285ba","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c94fead9f824dbbba848b571a99310a","value":231508}},"ec5f7ae733bc4da6a42dd35db2c680fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8707ac81fa764dd5b5f2351e17072b5e","placeholder":"​","style":"IPY_MODEL_d8d19b9e8ded48859ba8931474a8d570","value":" 226k/226k [00:00&lt;00:00, 325kB/s]"}},"7d57cb00c88f452f85ce334d311cf622":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf4e0c2a1394bb0a65807328cb20c81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98314b556d214d928f961ed26b7c8c60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a544b4b73bab48e5ba9b3811e3c285ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c94fead9f824dbbba848b571a99310a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8707ac81fa764dd5b5f2351e17072b5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8d19b9e8ded48859ba8931474a8d570":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb53974097714f43b66b258238b9a1a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d962c3d4af7d426aa6aa98185969f5ac","IPY_MODEL_52e91fbc4e0b4f769eefb85f0dcbcc21","IPY_MODEL_9967b0449bc54479869ec876ad10db48"],"layout":"IPY_MODEL_47e99224d8554c06ae9f762e9be1b7dd"}},"d962c3d4af7d426aa6aa98185969f5ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32fe215cb9ef4b338a44adf3dad69835","placeholder":"​","style":"IPY_MODEL_b9e0fc1dd604482aa0cde9ce7c5829cc","value":"Downloading: 100%"}},"52e91fbc4e0b4f769eefb85f0dcbcc21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37c183339b2b4e3cb1c89e0a702d6022","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f2dc566e546e423daed50d25b1062033","value":28}},"9967b0449bc54479869ec876ad10db48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62a7031fdb5c47fcb3c4b1b7c6e901e3","placeholder":"​","style":"IPY_MODEL_4c00ea71bd6243e4a87efefba1a64064","value":" 28.0/28.0 [00:00&lt;00:00, 1.05kB/s]"}},"47e99224d8554c06ae9f762e9be1b7dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32fe215cb9ef4b338a44adf3dad69835":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9e0fc1dd604482aa0cde9ce7c5829cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37c183339b2b4e3cb1c89e0a702d6022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2dc566e546e423daed50d25b1062033":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62a7031fdb5c47fcb3c4b1b7c6e901e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c00ea71bd6243e4a87efefba1a64064":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79a01119b70b411599d2cda3cbe721a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ef4f4f73fbdf41a4855004a20e045c0e","IPY_MODEL_30cf0c9e9a3c488b8cb093e1d98b99a2","IPY_MODEL_42e9f9a3defb41fba16ad3d831f0649a"],"layout":"IPY_MODEL_738d6098a84b49a38128d98ef256138a"}},"ef4f4f73fbdf41a4855004a20e045c0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc302568da294d469b211af28462c336","placeholder":"​","style":"IPY_MODEL_9afcb5077808434ba304390e30e822f8","value":"Downloading: 100%"}},"30cf0c9e9a3c488b8cb093e1d98b99a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_def3bbb5c9334a87872aefae96eab5a1","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_11ccefdfd47245f6b49a142605211d97","value":440473133}},"42e9f9a3defb41fba16ad3d831f0649a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06cbbcacb87140b2b60a322ab2a18324","placeholder":"​","style":"IPY_MODEL_2916d9ab49f24798aba92cf6c729ebcb","value":" 420M/420M [00:08&lt;00:00, 52.8MB/s]"}},"738d6098a84b49a38128d98ef256138a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc302568da294d469b211af28462c336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9afcb5077808434ba304390e30e822f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"def3bbb5c9334a87872aefae96eab5a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ccefdfd47245f6b49a142605211d97":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06cbbcacb87140b2b60a322ab2a18324":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2916d9ab49f24798aba92cf6c729ebcb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}